{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,Dataset, Subset\n",
    "import numpy as np\n",
    "import tft_model\n",
    "from data_formatters import ts_dataset  \n",
    "import data_formatters.base\n",
    "import expt_settings.configs\n",
    "import importlib\n",
    "from data_formatters import utils\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_formatters.utils' from '/Users/liuxufeng/github/tft/Temporal_Fusion_Transform/data_formatters/utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training from defined parameters for m4 ***\n",
      "Loading & splitting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuxufeng/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2198072, 13)\n",
      "Formatting train-valid-test splits.\n",
      "Setting scalers with training data...\n",
      "MT_001 5256 192\n",
      "MT_002 5256 192\n",
      "MT_003 5256 192\n",
      "MT_004 5256 192\n",
      "MT_005 5256 192\n",
      "MT_006 5256 192\n",
      "MT_007 5256 192\n",
      "MT_008 5256 192\n",
      "MT_009 5256 192\n",
      "MT_010 5256 192\n",
      "MT_011 5256 192\n",
      "MT_012 5256 192\n",
      "MT_013 5256 192\n",
      "MT_014 5256 192\n",
      "MT_015 5256 192\n",
      "MT_016 5256 192\n",
      "MT_017 5256 192\n",
      "MT_018 5256 192\n",
      "MT_019 5256 192\n",
      "MT_020 5256 192\n",
      "MT_021 5256 192\n",
      "MT_022 5256 192\n",
      "MT_023 5256 192\n",
      "MT_024 5256 192\n",
      "MT_025 5256 192\n",
      "MT_026 5256 192\n",
      "MT_027 5256 192\n",
      "MT_028 5256 192\n",
      "MT_029 5256 192\n",
      "MT_030 5256 192\n",
      "MT_031 5256 192\n",
      "MT_032 5256 192\n",
      "MT_033 5256 192\n",
      "MT_034 5256 192\n",
      "MT_035 5256 192\n",
      "MT_036 5256 192\n",
      "MT_037 5256 192\n",
      "MT_038 5256 192\n",
      "MT_039 5256 192\n",
      "MT_040 5256 192\n",
      "MT_041 5256 192\n",
      "MT_042 5256 192\n",
      "MT_043 5256 192\n",
      "MT_044 5256 192\n",
      "MT_045 5256 192\n",
      "MT_046 5256 192\n",
      "MT_047 5256 192\n",
      "MT_048 5256 192\n",
      "MT_049 5256 192\n",
      "MT_050 5256 192\n",
      "MT_051 5256 192\n",
      "MT_052 5256 192\n",
      "MT_053 5256 192\n",
      "MT_054 5256 192\n",
      "MT_055 5256 192\n",
      "MT_056 5256 192\n",
      "MT_057 5256 192\n",
      "MT_058 5256 192\n",
      "MT_059 5256 192\n",
      "MT_060 5256 192\n",
      "MT_061 5256 192\n",
      "MT_062 5256 192\n",
      "MT_063 5256 192\n",
      "MT_064 5256 192\n",
      "MT_065 5256 192\n",
      "MT_066 5256 192\n",
      "MT_067 5256 192\n",
      "MT_068 5256 192\n",
      "MT_069 5256 192\n",
      "MT_070 5256 192\n",
      "MT_071 5256 192\n",
      "MT_072 5256 192\n",
      "MT_073 5256 192\n",
      "MT_074 5256 192\n",
      "MT_075 5256 192\n",
      "MT_076 5256 192\n",
      "MT_077 5256 192\n",
      "MT_078 5256 192\n",
      "MT_079 5256 192\n",
      "MT_080 5256 192\n",
      "MT_081 5256 192\n",
      "MT_082 5256 192\n",
      "MT_083 5256 192\n",
      "MT_084 5256 192\n",
      "MT_085 5256 192\n",
      "MT_086 5256 192\n",
      "MT_087 5256 192\n",
      "MT_088 5256 192\n",
      "MT_089 5256 192\n",
      "MT_090 5256 192\n",
      "MT_091 5256 192\n",
      "MT_092 5256 192\n",
      "MT_093 5256 192\n",
      "MT_094 5256 192\n",
      "MT_095 5256 192\n",
      "MT_096 5256 192\n",
      "MT_097 5256 192\n",
      "MT_098 5256 192\n",
      "MT_099 5256 192\n",
      "MT_100 5256 192\n",
      "MT_101 5256 192\n",
      "MT_102 5256 192\n",
      "MT_103 5256 192\n",
      "MT_104 5256 192\n",
      "MT_105 5256 192\n",
      "MT_106 4944 192\n",
      "MT_107 4944 192\n",
      "MT_108 4944 192\n",
      "MT_109 4104 192\n",
      "MT_110 4944 192\n",
      "MT_111 4944 192\n",
      "MT_112 4248 192\n",
      "MT_113 4944 192\n",
      "MT_114 5256 192\n",
      "MT_115 4944 192\n",
      "MT_116 4104 192\n",
      "MT_117 4944 192\n",
      "MT_118 5256 192\n",
      "MT_119 5256 192\n",
      "MT_120 4944 192\n",
      "MT_121 4944 192\n",
      "MT_122 4944 192\n",
      "MT_123 5256 192\n",
      "MT_124 5256 192\n",
      "MT_125 5256 192\n",
      "MT_126 5256 192\n",
      "MT_127 5256 192\n",
      "MT_128 5256 192\n",
      "MT_129 5256 192\n",
      "MT_130 5256 192\n",
      "MT_131 5256 192\n",
      "MT_132 5256 192\n",
      "MT_133 3536 192\n",
      "MT_134 5256 192\n",
      "MT_135 5256 192\n",
      "MT_136 5256 192\n",
      "MT_137 5256 192\n",
      "MT_138 5256 192\n",
      "MT_139 5256 192\n",
      "MT_140 5256 192\n",
      "MT_141 5256 192\n",
      "MT_142 5256 192\n",
      "MT_143 5256 192\n",
      "MT_144 5256 192\n",
      "MT_145 5256 192\n",
      "MT_146 5256 192\n",
      "MT_147 5256 192\n",
      "MT_148 5256 192\n",
      "MT_149 5256 192\n",
      "MT_150 5256 192\n",
      "MT_151 5256 192\n",
      "MT_152 5256 192\n",
      "MT_153 5256 192\n",
      "MT_154 5256 192\n",
      "MT_155 5256 192\n",
      "MT_156 5256 192\n",
      "MT_157 5256 192\n",
      "MT_158 5256 192\n",
      "MT_159 5256 192\n",
      "MT_160 4440 192\n",
      "MT_161 5256 192\n",
      "MT_162 5256 192\n",
      "MT_163 5256 192\n",
      "MT_164 5256 192\n",
      "MT_165 5256 192\n",
      "MT_166 5256 192\n",
      "MT_167 5256 192\n",
      "MT_168 5256 192\n",
      "MT_169 5256 192\n",
      "MT_170 5256 192\n",
      "MT_171 5256 192\n",
      "MT_172 5256 192\n",
      "MT_173 5256 192\n",
      "MT_174 5256 192\n",
      "MT_175 5256 192\n",
      "MT_176 5256 192\n",
      "MT_177 5256 192\n",
      "MT_178 504 192\n",
      "MT_179 5256 192\n",
      "MT_180 5256 192\n",
      "MT_181 3744 192\n",
      "MT_182 5256 192\n",
      "MT_183 5256 192\n",
      "MT_184 5256 192\n",
      "MT_185 5256 192\n",
      "MT_186 5256 192\n",
      "MT_187 5256 192\n",
      "MT_188 5256 192\n",
      "MT_189 5256 192\n",
      "MT_190 5256 192\n",
      "MT_191 5256 192\n",
      "MT_192 5256 192\n",
      "MT_193 5256 192\n",
      "MT_194 5256 192\n",
      "MT_195 5256 192\n",
      "MT_196 5256 192\n",
      "MT_197 5256 192\n",
      "MT_198 5256 192\n",
      "MT_199 5256 192\n",
      "MT_200 5256 192\n",
      "MT_201 5256 192\n",
      "MT_202 5256 192\n",
      "MT_203 5256 192\n",
      "MT_204 5256 192\n",
      "MT_205 5256 192\n",
      "MT_206 5256 192\n",
      "MT_207 5256 192\n",
      "MT_208 5256 192\n",
      "MT_209 5256 192\n",
      "MT_210 5256 192\n",
      "MT_211 5256 192\n",
      "MT_212 5256 192\n",
      "MT_213 5256 192\n",
      "MT_214 5256 192\n",
      "MT_215 5256 192\n",
      "MT_216 5256 192\n",
      "MT_217 5256 192\n",
      "MT_218 5256 192\n",
      "MT_219 5256 192\n",
      "MT_220 5256 192\n",
      "MT_221 5256 192\n",
      "MT_222 5256 192\n",
      "MT_224 5256 192\n",
      "MT_225 5256 192\n",
      "MT_226 5256 192\n",
      "MT_227 5256 192\n",
      "MT_228 5256 192\n",
      "MT_229 5256 192\n",
      "MT_230 5256 192\n",
      "MT_231 5256 192\n",
      "MT_232 5256 192\n",
      "MT_233 5256 192\n",
      "MT_234 5256 192\n",
      "MT_235 5256 192\n",
      "MT_236 5256 192\n",
      "MT_237 5256 192\n",
      "MT_238 5256 192\n",
      "MT_239 5256 192\n",
      "MT_240 5256 192\n",
      "MT_241 5256 192\n",
      "MT_242 5256 192\n",
      "MT_243 5256 192\n",
      "MT_244 5256 192\n",
      "MT_245 5256 192\n",
      "MT_246 5256 192\n",
      "MT_247 5256 192\n",
      "MT_248 5256 192\n",
      "MT_249 5256 192\n",
      "MT_250 5256 192\n",
      "MT_251 5256 192\n",
      "MT_252 5256 192\n",
      "MT_253 5256 192\n",
      "MT_254 5256 192\n",
      "MT_255 5256 192\n",
      "MT_256 5256 192\n",
      "MT_257 5256 192\n",
      "MT_258 5256 192\n",
      "MT_259 5256 192\n",
      "MT_260 5256 192\n",
      "MT_261 5256 192\n",
      "MT_262 5256 192\n",
      "MT_263 5256 192\n",
      "MT_264 5256 192\n",
      "MT_265 5256 192\n",
      "MT_266 5256 192\n",
      "MT_267 5256 192\n",
      "MT_268 5256 192\n",
      "MT_269 5256 192\n",
      "MT_270 5256 192\n",
      "MT_271 5256 192\n",
      "MT_272 5256 192\n",
      "MT_273 5256 192\n",
      "MT_274 5256 192\n",
      "MT_275 5256 192\n",
      "MT_276 5256 192\n",
      "MT_277 5256 192\n",
      "MT_278 5256 192\n",
      "MT_279 5256 192\n",
      "MT_280 5256 192\n",
      "MT_281 5256 192\n",
      "MT_282 5256 192\n",
      "MT_283 5256 192\n",
      "MT_284 5256 192\n",
      "MT_285 5256 192\n",
      "MT_286 5256 192\n",
      "MT_287 5256 192\n",
      "MT_288 5256 192\n",
      "MT_289 5256 192\n",
      "MT_290 5256 192\n",
      "MT_291 5256 192\n",
      "MT_292 5256 192\n",
      "MT_293 5256 192\n",
      "MT_294 5256 192\n",
      "MT_295 5256 192\n",
      "MT_296 5256 192\n",
      "MT_297 5256 192\n",
      "MT_298 5256 192\n",
      "MT_299 5256 192\n",
      "MT_300 5256 192\n",
      "MT_301 5256 192\n",
      "MT_302 5256 192\n",
      "MT_303 5256 192\n",
      "MT_304 5256 192\n",
      "MT_305 5256 192\n",
      "MT_306 5256 192\n",
      "MT_307 5256 192\n",
      "MT_308 5256 192\n",
      "MT_309 5256 192\n",
      "MT_310 5256 192\n",
      "MT_311 5256 192\n",
      "MT_312 5256 192\n",
      "MT_313 5256 192\n",
      "MT_314 5256 192\n",
      "MT_315 5256 192\n",
      "MT_316 5256 192\n",
      "MT_317 5256 192\n",
      "MT_318 5256 192\n",
      "MT_319 5256 192\n",
      "MT_320 5256 192\n",
      "MT_321 5256 192\n",
      "MT_322 5256 192\n",
      "MT_323 5256 192\n",
      "MT_324 5256 192\n",
      "MT_325 5256 192\n",
      "MT_326 5256 192\n",
      "MT_327 5256 192\n",
      "MT_328 5256 192\n",
      "MT_329 5256 192\n",
      "MT_330 5256 192\n",
      "MT_331 5256 192\n",
      "MT_332 5256 192\n",
      "MT_333 5256 192\n",
      "MT_334 5256 192\n",
      "MT_335 5256 192\n",
      "MT_336 5256 192\n",
      "MT_337 4872 192\n",
      "MT_338 5256 192\n",
      "MT_339 5256 192\n",
      "MT_340 5256 192\n",
      "MT_341 5256 192\n",
      "MT_342 5256 192\n",
      "MT_343 5256 192\n",
      "MT_344 5256 192\n",
      "MT_345 5256 192\n",
      "MT_346 5256 192\n",
      "MT_347 5256 192\n",
      "MT_348 5256 192\n",
      "MT_349 5256 192\n",
      "MT_350 5256 192\n",
      "MT_351 5256 192\n",
      "MT_352 5256 192\n",
      "MT_353 5256 192\n",
      "MT_354 5256 192\n",
      "MT_355 5256 192\n",
      "MT_356 5256 192\n",
      "MT_357 5256 192\n",
      "MT_358 5256 192\n",
      "MT_359 5256 192\n",
      "MT_360 5256 192\n",
      "MT_361 5256 192\n",
      "MT_362 5256 192\n",
      "MT_363 5256 192\n",
      "MT_364 5256 192\n",
      "MT_365 5256 192\n",
      "MT_366 5256 192\n",
      "MT_367 5256 192\n",
      "MT_368 5256 192\n",
      "MT_369 5256 192\n",
      "MT_370 5256 192\n",
      "MT_001 744 192\n",
      "MT_002 744 192\n",
      "MT_003 744 192\n",
      "MT_004 744 192\n",
      "MT_005 744 192\n",
      "MT_006 744 192\n",
      "MT_007 744 192\n",
      "MT_008 744 192\n",
      "MT_009 744 192\n",
      "MT_010 744 192\n",
      "MT_011 744 192\n",
      "MT_012 744 192\n",
      "MT_013 744 192\n",
      "MT_014 744 192\n",
      "MT_015 744 192\n",
      "MT_016 744 192\n",
      "MT_017 744 192\n",
      "MT_018 744 192\n",
      "MT_019 744 192\n",
      "MT_020 744 192\n",
      "MT_021 744 192\n",
      "MT_022 744 192\n",
      "MT_023 744 192\n",
      "MT_024 744 192\n",
      "MT_025 744 192\n",
      "MT_026 744 192\n",
      "MT_027 744 192\n",
      "MT_028 744 192\n",
      "MT_029 744 192\n",
      "MT_030 744 192\n",
      "MT_031 744 192\n",
      "MT_032 744 192\n",
      "MT_033 744 192\n",
      "MT_034 744 192\n",
      "MT_035 744 192\n",
      "MT_036 744 192\n",
      "MT_037 744 192\n",
      "MT_038 744 192\n",
      "MT_039 744 192\n",
      "MT_040 744 192\n",
      "MT_041 744 192\n",
      "MT_042 744 192\n",
      "MT_043 744 192\n",
      "MT_044 744 192\n",
      "MT_045 744 192\n",
      "MT_046 744 192\n",
      "MT_047 744 192\n",
      "MT_048 744 192\n",
      "MT_049 744 192\n",
      "MT_050 744 192\n",
      "MT_051 744 192\n",
      "MT_052 744 192\n",
      "MT_053 744 192\n",
      "MT_054 744 192\n",
      "MT_055 744 192\n",
      "MT_056 744 192\n",
      "MT_057 744 192\n",
      "MT_058 744 192\n",
      "MT_059 744 192\n",
      "MT_060 744 192\n",
      "MT_061 744 192\n",
      "MT_062 744 192\n",
      "MT_063 744 192\n",
      "MT_064 744 192\n",
      "MT_065 744 192\n",
      "MT_066 744 192\n",
      "MT_067 744 192\n",
      "MT_068 744 192\n",
      "MT_069 744 192\n",
      "MT_070 744 192\n",
      "MT_071 744 192\n",
      "MT_072 744 192\n",
      "MT_073 744 192\n",
      "MT_074 744 192\n",
      "MT_075 744 192\n",
      "MT_076 744 192\n",
      "MT_077 744 192\n",
      "MT_078 744 192\n",
      "MT_079 744 192\n",
      "MT_080 744 192\n",
      "MT_081 744 192\n",
      "MT_082 744 192\n",
      "MT_083 744 192\n",
      "MT_084 744 192\n",
      "MT_085 744 192\n",
      "MT_086 744 192\n",
      "MT_087 744 192\n",
      "MT_088 744 192\n",
      "MT_089 744 192\n",
      "MT_090 744 192\n",
      "MT_091 744 192\n",
      "MT_092 744 192\n",
      "MT_093 744 192\n",
      "MT_094 744 192\n",
      "MT_095 744 192\n",
      "MT_096 744 192\n",
      "MT_097 744 192\n",
      "MT_098 744 192\n",
      "MT_099 744 192\n",
      "MT_100 744 192\n",
      "MT_101 744 192\n",
      "MT_102 744 192\n",
      "MT_103 744 192\n",
      "MT_104 744 192\n",
      "MT_105 744 192\n",
      "MT_106 744 192\n",
      "MT_107 744 192\n",
      "MT_108 744 192\n",
      "MT_109 744 192\n",
      "MT_110 744 192\n",
      "MT_111 744 192\n",
      "MT_112 744 192\n",
      "MT_113 744 192\n",
      "MT_114 744 192\n",
      "MT_115 744 192\n",
      "MT_116 744 192\n",
      "MT_117 744 192\n",
      "MT_118 744 192\n",
      "MT_119 744 192\n",
      "MT_120 744 192\n",
      "MT_121 744 192\n",
      "MT_122 744 192\n",
      "MT_123 744 192\n",
      "MT_124 744 192\n",
      "MT_125 744 192\n",
      "MT_126 744 192\n",
      "MT_127 744 192\n",
      "MT_128 744 192\n",
      "MT_129 744 192\n",
      "MT_130 744 192\n",
      "MT_131 744 192\n",
      "MT_132 744 192\n",
      "MT_133 744 192\n",
      "MT_134 744 192\n",
      "MT_135 744 192\n",
      "MT_136 744 192\n",
      "MT_137 744 192\n",
      "MT_138 744 192\n",
      "MT_139 744 192\n",
      "MT_140 744 192\n",
      "MT_141 744 192\n",
      "MT_142 744 192\n",
      "MT_143 744 192\n",
      "MT_144 744 192\n",
      "MT_145 744 192\n",
      "MT_146 744 192\n",
      "MT_147 744 192\n",
      "MT_148 744 192\n",
      "MT_149 744 192\n",
      "MT_150 744 192\n",
      "MT_151 744 192\n",
      "MT_152 744 192\n",
      "MT_153 744 192\n",
      "MT_154 744 192\n",
      "MT_155 744 192\n",
      "MT_156 744 192\n",
      "MT_157 744 192\n",
      "MT_158 744 192\n",
      "MT_159 744 192\n",
      "MT_160 744 192\n",
      "MT_161 744 192\n",
      "MT_162 744 192\n",
      "MT_163 744 192\n",
      "MT_164 744 192\n",
      "MT_165 744 192\n",
      "MT_166 744 192\n",
      "MT_167 744 192\n",
      "MT_168 744 192\n",
      "MT_169 744 192\n",
      "MT_170 744 192\n",
      "MT_171 744 192\n",
      "MT_172 744 192\n",
      "MT_173 744 192\n",
      "MT_174 744 192\n",
      "MT_175 744 192\n",
      "MT_176 744 192\n",
      "MT_177 744 192\n",
      "MT_178 744 192\n",
      "MT_179 744 192\n",
      "MT_180 744 192\n",
      "MT_181 744 192\n",
      "MT_182 744 192\n",
      "MT_183 744 192\n",
      "MT_184 744 192\n",
      "MT_185 744 192\n",
      "MT_186 744 192\n",
      "MT_187 744 192\n",
      "MT_188 744 192\n",
      "MT_189 744 192\n",
      "MT_190 744 192\n",
      "MT_191 744 192\n",
      "MT_192 744 192\n",
      "MT_193 744 192\n",
      "MT_194 744 192\n",
      "MT_195 744 192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT_196 744 192\n",
      "MT_197 744 192\n",
      "MT_198 744 192\n",
      "MT_199 744 192\n",
      "MT_200 744 192\n",
      "MT_201 744 192\n",
      "MT_202 744 192\n",
      "MT_203 744 192\n",
      "MT_204 744 192\n",
      "MT_205 744 192\n",
      "MT_206 744 192\n",
      "MT_207 744 192\n",
      "MT_208 744 192\n",
      "MT_209 744 192\n",
      "MT_210 744 192\n",
      "MT_211 744 192\n",
      "MT_212 744 192\n",
      "MT_213 744 192\n",
      "MT_214 744 192\n",
      "MT_215 744 192\n",
      "MT_216 744 192\n",
      "MT_217 744 192\n",
      "MT_218 744 192\n",
      "MT_219 744 192\n",
      "MT_220 744 192\n",
      "MT_221 744 192\n",
      "MT_222 744 192\n",
      "MT_224 744 192\n",
      "MT_225 744 192\n",
      "MT_226 744 192\n",
      "MT_227 744 192\n",
      "MT_228 744 192\n",
      "MT_229 744 192\n",
      "MT_230 744 192\n",
      "MT_231 744 192\n",
      "MT_232 744 192\n",
      "MT_233 744 192\n",
      "MT_234 744 192\n",
      "MT_235 744 192\n",
      "MT_236 744 192\n",
      "MT_237 744 192\n",
      "MT_238 744 192\n",
      "MT_239 744 192\n",
      "MT_240 744 192\n",
      "MT_241 744 192\n",
      "MT_242 744 192\n",
      "MT_243 744 192\n",
      "MT_244 744 192\n",
      "MT_245 744 192\n",
      "MT_246 744 192\n",
      "MT_247 744 192\n",
      "MT_248 744 192\n",
      "MT_249 744 192\n",
      "MT_250 744 192\n",
      "MT_251 744 192\n",
      "MT_252 744 192\n",
      "MT_253 744 192\n",
      "MT_254 744 192\n",
      "MT_255 744 192\n",
      "MT_256 744 192\n",
      "MT_257 744 192\n",
      "MT_258 744 192\n",
      "MT_259 744 192\n",
      "MT_260 744 192\n",
      "MT_261 744 192\n",
      "MT_262 744 192\n",
      "MT_263 744 192\n",
      "MT_264 744 192\n",
      "MT_265 744 192\n",
      "MT_266 744 192\n",
      "MT_267 744 192\n",
      "MT_268 744 192\n",
      "MT_269 744 192\n",
      "MT_270 744 192\n",
      "MT_271 744 192\n",
      "MT_272 744 192\n",
      "MT_273 744 192\n",
      "MT_274 744 192\n",
      "MT_275 744 192\n",
      "MT_276 744 192\n",
      "MT_277 744 192\n",
      "MT_278 744 192\n",
      "MT_279 744 192\n",
      "MT_280 744 192\n",
      "MT_281 744 192\n",
      "MT_282 744 192\n",
      "MT_283 744 192\n",
      "MT_284 744 192\n",
      "MT_285 744 192\n",
      "MT_286 744 192\n",
      "MT_287 744 192\n",
      "MT_288 744 192\n",
      "MT_289 744 192\n",
      "MT_290 744 192\n",
      "MT_291 744 192\n",
      "MT_292 744 192\n",
      "MT_293 744 192\n",
      "MT_294 744 192\n",
      "MT_295 744 192\n",
      "MT_296 744 192\n",
      "MT_297 744 192\n",
      "MT_298 744 192\n",
      "MT_299 744 192\n",
      "MT_300 744 192\n",
      "MT_301 744 192\n",
      "MT_302 744 192\n",
      "MT_303 744 192\n",
      "MT_304 744 192\n",
      "MT_305 744 192\n",
      "MT_306 744 192\n",
      "MT_307 744 192\n",
      "MT_308 744 192\n",
      "MT_309 744 192\n",
      "MT_310 744 192\n",
      "MT_311 744 192\n",
      "MT_312 744 192\n",
      "MT_313 744 192\n",
      "MT_314 744 192\n",
      "MT_315 744 192\n",
      "MT_316 744 192\n",
      "MT_317 744 192\n",
      "MT_318 744 192\n",
      "MT_319 744 192\n",
      "MT_320 744 192\n",
      "MT_321 744 192\n",
      "MT_322 744 192\n",
      "MT_323 744 192\n",
      "MT_324 744 192\n",
      "MT_325 744 192\n",
      "MT_326 744 192\n",
      "MT_327 744 192\n",
      "MT_328 744 192\n",
      "MT_329 744 192\n",
      "MT_330 744 192\n",
      "MT_331 744 192\n",
      "MT_332 744 192\n",
      "MT_333 744 192\n",
      "MT_334 744 192\n",
      "MT_335 744 192\n",
      "MT_336 744 192\n",
      "MT_337 744 192\n",
      "MT_338 744 192\n",
      "MT_339 744 192\n",
      "MT_340 744 192\n",
      "MT_341 744 192\n",
      "MT_342 744 192\n",
      "MT_343 744 192\n",
      "MT_344 744 192\n",
      "MT_345 744 192\n",
      "MT_346 744 192\n",
      "MT_347 744 192\n",
      "MT_348 744 192\n",
      "MT_349 744 192\n",
      "MT_350 744 192\n",
      "MT_351 744 192\n",
      "MT_352 744 192\n",
      "MT_353 744 192\n",
      "MT_354 744 192\n",
      "MT_355 744 192\n",
      "MT_356 744 192\n",
      "MT_357 744 192\n",
      "MT_358 744 192\n",
      "MT_359 744 192\n",
      "MT_360 744 192\n",
      "MT_361 744 192\n",
      "MT_362 744 192\n",
      "MT_363 744 192\n",
      "MT_364 744 192\n",
      "MT_365 744 192\n",
      "MT_366 744 192\n",
      "MT_367 744 192\n",
      "MT_368 744 192\n",
      "MT_369 744 192\n",
      "MT_370 744 192\n",
      "MT_001 336 192\n",
      "MT_002 336 192\n",
      "MT_003 336 192\n",
      "MT_004 336 192\n",
      "MT_005 336 192\n",
      "MT_006 336 192\n",
      "MT_007 336 192\n",
      "MT_008 336 192\n",
      "MT_009 336 192\n",
      "MT_010 336 192\n",
      "MT_011 336 192\n",
      "MT_012 336 192\n",
      "MT_013 336 192\n",
      "MT_014 336 192\n",
      "MT_015 336 192\n",
      "MT_016 336 192\n",
      "MT_017 336 192\n",
      "MT_018 336 192\n",
      "MT_019 336 192\n",
      "MT_020 336 192\n",
      "MT_021 336 192\n",
      "MT_022 336 192\n",
      "MT_023 336 192\n",
      "MT_024 336 192\n",
      "MT_025 336 192\n",
      "MT_026 336 192\n",
      "MT_027 336 192\n",
      "MT_028 336 192\n",
      "MT_029 336 192\n",
      "MT_030 336 192\n",
      "MT_031 336 192\n",
      "MT_032 336 192\n",
      "MT_033 336 192\n",
      "MT_034 336 192\n",
      "MT_035 336 192\n",
      "MT_036 336 192\n",
      "MT_037 336 192\n",
      "MT_038 336 192\n",
      "MT_039 336 192\n",
      "MT_040 336 192\n",
      "MT_041 336 192\n",
      "MT_042 336 192\n",
      "MT_043 336 192\n",
      "MT_044 336 192\n",
      "MT_045 336 192\n",
      "MT_046 336 192\n",
      "MT_047 336 192\n",
      "MT_048 336 192\n",
      "MT_049 336 192\n",
      "MT_050 336 192\n",
      "MT_051 336 192\n",
      "MT_052 336 192\n",
      "MT_053 336 192\n",
      "MT_054 336 192\n",
      "MT_055 336 192\n",
      "MT_056 336 192\n",
      "MT_057 336 192\n",
      "MT_058 336 192\n",
      "MT_059 336 192\n",
      "MT_060 336 192\n",
      "MT_061 336 192\n",
      "MT_062 336 192\n",
      "MT_063 336 192\n",
      "MT_064 336 192\n",
      "MT_065 336 192\n",
      "MT_066 336 192\n",
      "MT_067 336 192\n",
      "MT_068 336 192\n",
      "MT_069 336 192\n",
      "MT_070 336 192\n",
      "MT_071 336 192\n",
      "MT_072 336 192\n",
      "MT_073 336 192\n",
      "MT_074 336 192\n",
      "MT_075 336 192\n",
      "MT_076 336 192\n",
      "MT_077 336 192\n",
      "MT_078 336 192\n",
      "MT_079 336 192\n",
      "MT_080 336 192\n",
      "MT_081 336 192\n",
      "MT_082 336 192\n",
      "MT_083 336 192\n",
      "MT_084 336 192\n",
      "MT_085 336 192\n",
      "MT_086 336 192\n",
      "MT_087 336 192\n",
      "MT_088 336 192\n",
      "MT_089 336 192\n",
      "MT_090 336 192\n",
      "MT_091 336 192\n",
      "MT_092 336 192\n",
      "MT_093 336 192\n",
      "MT_094 336 192\n",
      "MT_095 336 192\n",
      "MT_096 336 192\n",
      "MT_097 336 192\n",
      "MT_098 336 192\n",
      "MT_099 336 192\n",
      "MT_100 336 192\n",
      "MT_101 336 192\n",
      "MT_102 336 192\n",
      "MT_103 336 192\n",
      "MT_104 336 192\n",
      "MT_105 336 192\n",
      "MT_106 336 192\n",
      "MT_107 336 192\n",
      "MT_108 336 192\n",
      "MT_109 336 192\n",
      "MT_110 336 192\n",
      "MT_111 336 192\n",
      "MT_112 336 192\n",
      "MT_113 336 192\n",
      "MT_114 336 192\n",
      "MT_115 336 192\n",
      "MT_116 336 192\n",
      "MT_117 336 192\n",
      "MT_118 336 192\n",
      "MT_119 336 192\n",
      "MT_120 336 192\n",
      "MT_121 336 192\n",
      "MT_122 336 192\n",
      "MT_123 336 192\n",
      "MT_124 336 192\n",
      "MT_125 336 192\n",
      "MT_126 336 192\n",
      "MT_127 336 192\n",
      "MT_128 336 192\n",
      "MT_129 336 192\n",
      "MT_130 336 192\n",
      "MT_131 336 192\n",
      "MT_132 336 192\n",
      "MT_133 336 192\n",
      "MT_134 336 192\n",
      "MT_135 336 192\n",
      "MT_136 336 192\n",
      "MT_137 336 192\n",
      "MT_138 336 192\n",
      "MT_139 336 192\n",
      "MT_140 336 192\n",
      "MT_141 336 192\n",
      "MT_142 336 192\n",
      "MT_143 336 192\n",
      "MT_144 336 192\n",
      "MT_145 336 192\n",
      "MT_146 336 192\n",
      "MT_147 336 192\n",
      "MT_148 336 192\n",
      "MT_149 336 192\n",
      "MT_150 336 192\n",
      "MT_151 336 192\n",
      "MT_152 336 192\n",
      "MT_153 336 192\n",
      "MT_154 336 192\n",
      "MT_155 336 192\n",
      "MT_156 336 192\n",
      "MT_157 336 192\n",
      "MT_158 336 192\n",
      "MT_159 336 192\n",
      "MT_160 336 192\n",
      "MT_161 336 192\n",
      "MT_162 336 192\n",
      "MT_163 336 192\n",
      "MT_164 336 192\n",
      "MT_165 336 192\n",
      "MT_166 336 192\n",
      "MT_167 336 192\n",
      "MT_168 336 192\n",
      "MT_169 336 192\n",
      "MT_170 336 192\n",
      "MT_171 336 192\n",
      "MT_172 336 192\n",
      "MT_173 336 192\n",
      "MT_174 336 192\n",
      "MT_175 336 192\n",
      "MT_176 336 192\n",
      "MT_177 336 192\n",
      "MT_178 336 192\n",
      "MT_179 336 192\n",
      "MT_180 336 192\n",
      "MT_181 336 192\n",
      "MT_182 336 192\n",
      "MT_183 336 192\n",
      "MT_184 336 192\n",
      "MT_185 336 192\n",
      "MT_186 336 192\n",
      "MT_187 336 192\n",
      "MT_188 336 192\n",
      "MT_189 336 192\n",
      "MT_190 336 192\n",
      "MT_191 336 192\n",
      "MT_192 336 192\n",
      "MT_193 336 192\n",
      "MT_194 336 192\n",
      "MT_195 336 192\n",
      "MT_196 336 192\n",
      "MT_197 336 192\n",
      "MT_198 336 192\n",
      "MT_199 336 192\n",
      "MT_200 336 192\n",
      "MT_201 336 192\n",
      "MT_202 336 192\n",
      "MT_203 336 192\n",
      "MT_204 336 192\n",
      "MT_205 336 192\n",
      "MT_206 336 192\n",
      "MT_207 336 192\n",
      "MT_208 336 192\n",
      "MT_209 336 192\n",
      "MT_210 336 192\n",
      "MT_211 336 192\n",
      "MT_212 336 192\n",
      "MT_213 336 192\n",
      "MT_214 336 192\n",
      "MT_215 336 192\n",
      "MT_216 336 192\n",
      "MT_217 336 192\n",
      "MT_218 336 192\n",
      "MT_219 336 192\n",
      "MT_220 336 192\n",
      "MT_221 336 192\n",
      "MT_222 336 192\n",
      "MT_224 336 192\n",
      "MT_225 336 192\n",
      "MT_226 336 192\n",
      "MT_227 336 192\n",
      "MT_228 336 192\n",
      "MT_229 336 192\n",
      "MT_230 336 192\n",
      "MT_231 336 192\n",
      "MT_232 336 192\n",
      "MT_233 336 192\n",
      "MT_234 336 192\n",
      "MT_235 336 192\n",
      "MT_236 336 192\n",
      "MT_237 336 192\n",
      "MT_238 336 192\n",
      "MT_239 336 192\n",
      "MT_240 336 192\n",
      "MT_241 336 192\n",
      "MT_242 336 192\n",
      "MT_243 336 192\n",
      "MT_244 336 192\n",
      "MT_245 336 192\n",
      "MT_246 336 192\n",
      "MT_247 336 192\n",
      "MT_248 336 192\n",
      "MT_249 336 192\n",
      "MT_250 336 192\n",
      "MT_251 336 192\n",
      "MT_252 336 192\n",
      "MT_253 336 192\n",
      "MT_254 336 192\n",
      "MT_255 336 192\n",
      "MT_256 336 192\n",
      "MT_257 336 192\n",
      "MT_258 336 192\n",
      "MT_259 336 192\n",
      "MT_260 336 192\n",
      "MT_261 336 192\n",
      "MT_262 336 192\n",
      "MT_263 336 192\n",
      "MT_264 336 192\n",
      "MT_265 336 192\n",
      "MT_266 336 192\n",
      "MT_267 336 192\n",
      "MT_268 336 192\n",
      "MT_269 336 192\n",
      "MT_270 336 192\n",
      "MT_271 336 192\n",
      "MT_272 336 192\n",
      "MT_273 336 192\n",
      "MT_274 336 192\n",
      "MT_275 336 192\n",
      "MT_276 336 192\n",
      "MT_277 336 192\n",
      "MT_278 336 192\n",
      "MT_279 336 192\n",
      "MT_280 336 192\n",
      "MT_281 336 192\n",
      "MT_282 336 192\n",
      "MT_283 336 192\n",
      "MT_284 336 192\n",
      "MT_285 336 192\n",
      "MT_286 336 192\n",
      "MT_287 336 192\n",
      "MT_288 336 192\n",
      "MT_289 336 192\n",
      "MT_290 336 192\n",
      "MT_291 336 192\n",
      "MT_292 336 192\n",
      "MT_293 336 192\n",
      "MT_294 336 192\n",
      "MT_295 336 192\n",
      "MT_296 336 192\n",
      "MT_297 336 192\n",
      "MT_298 336 192\n",
      "MT_299 336 192\n",
      "MT_300 336 192\n",
      "MT_301 336 192\n",
      "MT_302 336 192\n",
      "MT_303 336 192\n",
      "MT_304 336 192\n",
      "MT_305 336 192\n",
      "MT_306 336 192\n",
      "MT_307 336 192\n",
      "MT_308 336 192\n",
      "MT_309 336 192\n",
      "MT_310 336 192\n",
      "MT_311 336 192\n",
      "MT_312 336 192\n",
      "MT_313 336 192\n",
      "MT_314 336 192\n",
      "MT_315 336 192\n",
      "MT_316 336 192\n",
      "MT_317 336 192\n",
      "MT_318 336 192\n",
      "MT_319 336 192\n",
      "MT_320 336 192\n",
      "MT_321 336 192\n",
      "MT_322 336 192\n",
      "MT_323 336 192\n",
      "MT_324 336 192\n",
      "MT_325 336 192\n",
      "MT_326 336 192\n",
      "MT_327 336 192\n",
      "MT_328 336 192\n",
      "MT_329 336 192\n",
      "MT_330 336 192\n",
      "MT_331 336 192\n",
      "MT_332 336 192\n",
      "MT_333 336 192\n",
      "MT_334 336 192\n",
      "MT_335 336 192\n",
      "MT_336 336 192\n",
      "MT_337 336 192\n",
      "MT_338 336 192\n",
      "MT_339 336 192\n",
      "MT_340 336 192\n",
      "MT_341 336 192\n",
      "MT_342 336 192\n",
      "MT_343 336 192\n",
      "MT_344 336 192\n",
      "MT_345 336 192\n",
      "MT_346 336 192\n",
      "MT_347 336 192\n",
      "MT_348 336 192\n",
      "MT_349 336 192\n",
      "MT_350 336 192\n",
      "MT_351 336 192\n",
      "MT_352 336 192\n",
      "MT_353 336 192\n",
      "MT_354 336 192\n",
      "MT_355 336 192\n",
      "MT_356 336 192\n",
      "MT_357 336 192\n",
      "MT_358 336 192\n",
      "MT_359 336 192\n",
      "MT_360 336 192\n",
      "MT_361 336 192\n",
      "MT_362 336 192\n",
      "MT_363 336 192\n",
      "MT_364 336 192\n",
      "MT_365 336 192\n",
      "MT_366 336 192\n",
      "MT_367 336 192\n",
      "MT_368 336 192\n",
      "MT_369 336 192\n",
      "MT_370 336 192\n",
      "8.665380001068115\n"
     ]
    }
   ],
   "source": [
    "ExperimentConfig = expt_settings.configs.ExperimentConfig\n",
    "\n",
    "config = ExperimentConfig('electricity', 'outputs')\n",
    "\n",
    "data_formatter = config.make_data_formatter()\n",
    "\n",
    "\n",
    "print(\"*** Training from defined parameters for {} ***\".format('m4'))\n",
    "data_csv_path = \"./electricity/hourly_electricity.csv\"\n",
    "#data_csv_path = '/Users/ardakeskiner/Desktop/TUM/Courses/ws19_20/tft/tft_outputs/data/electricity/hourly_electricity.csv'\n",
    "print(\"Loading & splitting data...\")\n",
    "raw_data = pd.read_csv(data_csv_path, index_col=0)\n",
    "print(raw_data.shape)\n",
    "start = time.time()\n",
    "train, valid, test = data_formatter.split_data(raw_data)\n",
    "train_samples, valid_samples = data_formatter.get_num_samples_for_calibration()\n",
    "print(time.time()-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_usage</th>\n",
       "      <th>t</th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>categorical_id</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>hours_from_start</th>\n",
       "      <th>categorical_day_of_week</th>\n",
       "      <th>categorical_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17544</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26304.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26304.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17545</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26305.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26305.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17546</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26306.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 02:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26306.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17547</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26307.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 03:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26307.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17548</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26308.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 04:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26308.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17549</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26309.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 05:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26309.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17550</th>\n",
       "      <td>3.172589</td>\n",
       "      <td>26310.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 06:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26310.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17551</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26311.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 07:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26311.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17552</th>\n",
       "      <td>1.269036</td>\n",
       "      <td>26312.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 08:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26312.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17553</th>\n",
       "      <td>0.317259</td>\n",
       "      <td>26313.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 09:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26313.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17554</th>\n",
       "      <td>0.634518</td>\n",
       "      <td>26314.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 10:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26314.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17555</th>\n",
       "      <td>0.317259</td>\n",
       "      <td>26315.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 11:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17556</th>\n",
       "      <td>0.634518</td>\n",
       "      <td>26316.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 12:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26316.0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17557</th>\n",
       "      <td>0.317259</td>\n",
       "      <td>26317.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 13:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26317.0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17558</th>\n",
       "      <td>0.317259</td>\n",
       "      <td>26318.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 14:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26318.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>0.634518</td>\n",
       "      <td>26319.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 15:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26319.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17560</th>\n",
       "      <td>2.220812</td>\n",
       "      <td>26320.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 16:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26320.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17561</th>\n",
       "      <td>2.220812</td>\n",
       "      <td>26321.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 17:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26321.0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17562</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26322.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 18:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26322.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17563</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26323.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 19:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26323.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17564</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26324.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 20:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26324.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17565</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26325.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 21:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26325.0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17566</th>\n",
       "      <td>3.172589</td>\n",
       "      <td>26326.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 22:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26326.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17567</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26327.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 23:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26327.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17568</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26328.0</td>\n",
       "      <td>1097</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-02 00:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26328.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17569</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26329.0</td>\n",
       "      <td>1097</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-02 01:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26329.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17570</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26330.0</td>\n",
       "      <td>1097</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-02 02:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26330.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17571</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26331.0</td>\n",
       "      <td>1097</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-02 03:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26331.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17572</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26332.0</td>\n",
       "      <td>1097</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-02 04:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26332.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17573</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26333.0</td>\n",
       "      <td>1097</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-02 05:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26333.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       power_usage        t  days_from_start categorical_id  \\\n",
       "17544     2.538071  26304.0             1096         MT_001   \n",
       "17545     2.855330  26305.0             1096         MT_001   \n",
       "17546     2.855330  26306.0             1096         MT_001   \n",
       "17547     2.855330  26307.0             1096         MT_001   \n",
       "17548     2.538071  26308.0             1096         MT_001   \n",
       "17549     2.538071  26309.0             1096         MT_001   \n",
       "17550     3.172589  26310.0             1096         MT_001   \n",
       "17551     2.855330  26311.0             1096         MT_001   \n",
       "17552     1.269036  26312.0             1096         MT_001   \n",
       "17553     0.317259  26313.0             1096         MT_001   \n",
       "17554     0.634518  26314.0             1096         MT_001   \n",
       "17555     0.317259  26315.0             1096         MT_001   \n",
       "17556     0.634518  26316.0             1096         MT_001   \n",
       "17557     0.317259  26317.0             1096         MT_001   \n",
       "17558     0.317259  26318.0             1096         MT_001   \n",
       "17559     0.634518  26319.0             1096         MT_001   \n",
       "17560     2.220812  26320.0             1096         MT_001   \n",
       "17561     2.220812  26321.0             1096         MT_001   \n",
       "17562     2.855330  26322.0             1096         MT_001   \n",
       "17563     2.855330  26323.0             1096         MT_001   \n",
       "17564     2.538071  26324.0             1096         MT_001   \n",
       "17565     2.538071  26325.0             1096         MT_001   \n",
       "17566     3.172589  26326.0             1096         MT_001   \n",
       "17567     2.538071  26327.0             1096         MT_001   \n",
       "17568     2.538071  26328.0             1097         MT_001   \n",
       "17569     2.855330  26329.0             1097         MT_001   \n",
       "17570     2.855330  26330.0             1097         MT_001   \n",
       "17571     2.538071  26331.0             1097         MT_001   \n",
       "17572     2.855330  26332.0             1097         MT_001   \n",
       "17573     2.855330  26333.0             1097         MT_001   \n",
       "\n",
       "                      date      id  hour  day  day_of_week  month  \\\n",
       "17544  2014-01-01 00:00:00  MT_001     0    1            2      1   \n",
       "17545  2014-01-01 01:00:00  MT_001     1    1            2      1   \n",
       "17546  2014-01-01 02:00:00  MT_001     2    1            2      1   \n",
       "17547  2014-01-01 03:00:00  MT_001     3    1            2      1   \n",
       "17548  2014-01-01 04:00:00  MT_001     4    1            2      1   \n",
       "17549  2014-01-01 05:00:00  MT_001     5    1            2      1   \n",
       "17550  2014-01-01 06:00:00  MT_001     6    1            2      1   \n",
       "17551  2014-01-01 07:00:00  MT_001     7    1            2      1   \n",
       "17552  2014-01-01 08:00:00  MT_001     8    1            2      1   \n",
       "17553  2014-01-01 09:00:00  MT_001     9    1            2      1   \n",
       "17554  2014-01-01 10:00:00  MT_001    10    1            2      1   \n",
       "17555  2014-01-01 11:00:00  MT_001    11    1            2      1   \n",
       "17556  2014-01-01 12:00:00  MT_001    12    1            2      1   \n",
       "17557  2014-01-01 13:00:00  MT_001    13    1            2      1   \n",
       "17558  2014-01-01 14:00:00  MT_001    14    1            2      1   \n",
       "17559  2014-01-01 15:00:00  MT_001    15    1            2      1   \n",
       "17560  2014-01-01 16:00:00  MT_001    16    1            2      1   \n",
       "17561  2014-01-01 17:00:00  MT_001    17    1            2      1   \n",
       "17562  2014-01-01 18:00:00  MT_001    18    1            2      1   \n",
       "17563  2014-01-01 19:00:00  MT_001    19    1            2      1   \n",
       "17564  2014-01-01 20:00:00  MT_001    20    1            2      1   \n",
       "17565  2014-01-01 21:00:00  MT_001    21    1            2      1   \n",
       "17566  2014-01-01 22:00:00  MT_001    22    1            2      1   \n",
       "17567  2014-01-01 23:00:00  MT_001    23    1            2      1   \n",
       "17568  2014-01-02 00:00:00  MT_001     0    2            3      1   \n",
       "17569  2014-01-02 01:00:00  MT_001     1    2            3      1   \n",
       "17570  2014-01-02 02:00:00  MT_001     2    2            3      1   \n",
       "17571  2014-01-02 03:00:00  MT_001     3    2            3      1   \n",
       "17572  2014-01-02 04:00:00  MT_001     4    2            3      1   \n",
       "17573  2014-01-02 05:00:00  MT_001     5    2            3      1   \n",
       "\n",
       "       hours_from_start  categorical_day_of_week  categorical_hour  \n",
       "17544           26304.0                        2                 0  \n",
       "17545           26305.0                        2                 1  \n",
       "17546           26306.0                        2                 2  \n",
       "17547           26307.0                        2                 3  \n",
       "17548           26308.0                        2                 4  \n",
       "17549           26309.0                        2                 5  \n",
       "17550           26310.0                        2                 6  \n",
       "17551           26311.0                        2                 7  \n",
       "17552           26312.0                        2                 8  \n",
       "17553           26313.0                        2                 9  \n",
       "17554           26314.0                        2                10  \n",
       "17555           26315.0                        2                11  \n",
       "17556           26316.0                        2                12  \n",
       "17557           26317.0                        2                13  \n",
       "17558           26318.0                        2                14  \n",
       "17559           26319.0                        2                15  \n",
       "17560           26320.0                        2                16  \n",
       "17561           26321.0                        2                17  \n",
       "17562           26322.0                        2                18  \n",
       "17563           26323.0                        2                19  \n",
       "17564           26324.0                        2                20  \n",
       "17565           26325.0                        2                21  \n",
       "17566           26326.0                        2                22  \n",
       "17567           26327.0                        2                23  \n",
       "17568           26328.0                        3                 0  \n",
       "17569           26329.0                        3                 1  \n",
       "17570           26330.0                        3                 2  \n",
       "17571           26331.0                        3                 3  \n",
       "17572           26332.0                        3                 4  \n",
       "17573           26333.0                        3                 5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.198072e+06\n",
       "mean     6.169692e+02\n",
       "std      3.632925e+03\n",
       "min      0.000000e+00\n",
       "25%      5.149182e+01\n",
       "50%      1.208142e+02\n",
       "75%      3.076074e+02\n",
       "max      1.681000e+05\n",
       "Name: power_usage, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[\"power_usage\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1096, 1345)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data[\"days_from_start\"].min(), raw_data[\"days_from_start\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1096, 1314)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"days_from_start\"].min(), train[\"days_from_start\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1308, 1338)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[\"days_from_start\"].min(), valid[\"days_from_start\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1332, 1345)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"days_from_start\"].min(), test[\"days_from_start\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450000, 50000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples, valid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up default params\n",
    "fixed_params = data_formatter.get_experiment_params()\n",
    "params = data_formatter.get_default_model_params()\n",
    "\n",
    "fixed_params.update(params)\n",
    "fixed_params['batch_first'] = True\n",
    "fixed_params['name'] = 'test'\n",
    "fixed_params['device'] = 'cpu' # torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# fixed_params['minibatch_size'] = 64\n",
    "# fixed_params['category_count'] = [6]\n",
    "device = fixed_params['device']\n",
    "fixed_params['quantiles'] = [0.5]\n",
    "\n",
    "# with open('data_formatter_m4.pkl', 'wb') as output:  # Overwrites any existing file.\n",
    "#     pickle.dump(data_formatter, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MT_001': StandardScaler(),\n",
       " 'MT_002': StandardScaler(),\n",
       " 'MT_003': StandardScaler(),\n",
       " 'MT_004': StandardScaler(),\n",
       " 'MT_005': StandardScaler(),\n",
       " 'MT_006': StandardScaler(),\n",
       " 'MT_007': StandardScaler(),\n",
       " 'MT_008': StandardScaler(),\n",
       " 'MT_009': StandardScaler(),\n",
       " 'MT_010': StandardScaler(),\n",
       " 'MT_011': StandardScaler(),\n",
       " 'MT_012': StandardScaler(),\n",
       " 'MT_013': StandardScaler(),\n",
       " 'MT_014': StandardScaler(),\n",
       " 'MT_015': StandardScaler(),\n",
       " 'MT_016': StandardScaler(),\n",
       " 'MT_017': StandardScaler(),\n",
       " 'MT_018': StandardScaler(),\n",
       " 'MT_019': StandardScaler(),\n",
       " 'MT_020': StandardScaler(),\n",
       " 'MT_021': StandardScaler(),\n",
       " 'MT_022': StandardScaler(),\n",
       " 'MT_023': StandardScaler(),\n",
       " 'MT_024': StandardScaler(),\n",
       " 'MT_025': StandardScaler(),\n",
       " 'MT_026': StandardScaler(),\n",
       " 'MT_027': StandardScaler(),\n",
       " 'MT_028': StandardScaler(),\n",
       " 'MT_029': StandardScaler(),\n",
       " 'MT_030': StandardScaler(),\n",
       " 'MT_031': StandardScaler(),\n",
       " 'MT_032': StandardScaler(),\n",
       " 'MT_033': StandardScaler(),\n",
       " 'MT_034': StandardScaler(),\n",
       " 'MT_035': StandardScaler(),\n",
       " 'MT_036': StandardScaler(),\n",
       " 'MT_037': StandardScaler(),\n",
       " 'MT_038': StandardScaler(),\n",
       " 'MT_039': StandardScaler(),\n",
       " 'MT_040': StandardScaler(),\n",
       " 'MT_041': StandardScaler(),\n",
       " 'MT_042': StandardScaler(),\n",
       " 'MT_043': StandardScaler(),\n",
       " 'MT_044': StandardScaler(),\n",
       " 'MT_045': StandardScaler(),\n",
       " 'MT_046': StandardScaler(),\n",
       " 'MT_047': StandardScaler(),\n",
       " 'MT_048': StandardScaler(),\n",
       " 'MT_049': StandardScaler(),\n",
       " 'MT_050': StandardScaler(),\n",
       " 'MT_051': StandardScaler(),\n",
       " 'MT_052': StandardScaler(),\n",
       " 'MT_053': StandardScaler(),\n",
       " 'MT_054': StandardScaler(),\n",
       " 'MT_055': StandardScaler(),\n",
       " 'MT_056': StandardScaler(),\n",
       " 'MT_057': StandardScaler(),\n",
       " 'MT_058': StandardScaler(),\n",
       " 'MT_059': StandardScaler(),\n",
       " 'MT_060': StandardScaler(),\n",
       " 'MT_061': StandardScaler(),\n",
       " 'MT_062': StandardScaler(),\n",
       " 'MT_063': StandardScaler(),\n",
       " 'MT_064': StandardScaler(),\n",
       " 'MT_065': StandardScaler(),\n",
       " 'MT_066': StandardScaler(),\n",
       " 'MT_067': StandardScaler(),\n",
       " 'MT_068': StandardScaler(),\n",
       " 'MT_069': StandardScaler(),\n",
       " 'MT_070': StandardScaler(),\n",
       " 'MT_071': StandardScaler(),\n",
       " 'MT_072': StandardScaler(),\n",
       " 'MT_073': StandardScaler(),\n",
       " 'MT_074': StandardScaler(),\n",
       " 'MT_075': StandardScaler(),\n",
       " 'MT_076': StandardScaler(),\n",
       " 'MT_077': StandardScaler(),\n",
       " 'MT_078': StandardScaler(),\n",
       " 'MT_079': StandardScaler(),\n",
       " 'MT_080': StandardScaler(),\n",
       " 'MT_081': StandardScaler(),\n",
       " 'MT_082': StandardScaler(),\n",
       " 'MT_083': StandardScaler(),\n",
       " 'MT_084': StandardScaler(),\n",
       " 'MT_085': StandardScaler(),\n",
       " 'MT_086': StandardScaler(),\n",
       " 'MT_087': StandardScaler(),\n",
       " 'MT_088': StandardScaler(),\n",
       " 'MT_089': StandardScaler(),\n",
       " 'MT_090': StandardScaler(),\n",
       " 'MT_091': StandardScaler(),\n",
       " 'MT_092': StandardScaler(),\n",
       " 'MT_093': StandardScaler(),\n",
       " 'MT_094': StandardScaler(),\n",
       " 'MT_095': StandardScaler(),\n",
       " 'MT_096': StandardScaler(),\n",
       " 'MT_097': StandardScaler(),\n",
       " 'MT_098': StandardScaler(),\n",
       " 'MT_099': StandardScaler(),\n",
       " 'MT_100': StandardScaler(),\n",
       " 'MT_101': StandardScaler(),\n",
       " 'MT_102': StandardScaler(),\n",
       " 'MT_103': StandardScaler(),\n",
       " 'MT_104': StandardScaler(),\n",
       " 'MT_105': StandardScaler(),\n",
       " 'MT_106': StandardScaler(),\n",
       " 'MT_107': StandardScaler(),\n",
       " 'MT_108': StandardScaler(),\n",
       " 'MT_109': StandardScaler(),\n",
       " 'MT_110': StandardScaler(),\n",
       " 'MT_111': StandardScaler(),\n",
       " 'MT_112': StandardScaler(),\n",
       " 'MT_113': StandardScaler(),\n",
       " 'MT_114': StandardScaler(),\n",
       " 'MT_115': StandardScaler(),\n",
       " 'MT_116': StandardScaler(),\n",
       " 'MT_117': StandardScaler(),\n",
       " 'MT_118': StandardScaler(),\n",
       " 'MT_119': StandardScaler(),\n",
       " 'MT_120': StandardScaler(),\n",
       " 'MT_121': StandardScaler(),\n",
       " 'MT_122': StandardScaler(),\n",
       " 'MT_123': StandardScaler(),\n",
       " 'MT_124': StandardScaler(),\n",
       " 'MT_125': StandardScaler(),\n",
       " 'MT_126': StandardScaler(),\n",
       " 'MT_127': StandardScaler(),\n",
       " 'MT_128': StandardScaler(),\n",
       " 'MT_129': StandardScaler(),\n",
       " 'MT_130': StandardScaler(),\n",
       " 'MT_131': StandardScaler(),\n",
       " 'MT_132': StandardScaler(),\n",
       " 'MT_133': StandardScaler(),\n",
       " 'MT_134': StandardScaler(),\n",
       " 'MT_135': StandardScaler(),\n",
       " 'MT_136': StandardScaler(),\n",
       " 'MT_137': StandardScaler(),\n",
       " 'MT_138': StandardScaler(),\n",
       " 'MT_139': StandardScaler(),\n",
       " 'MT_140': StandardScaler(),\n",
       " 'MT_141': StandardScaler(),\n",
       " 'MT_142': StandardScaler(),\n",
       " 'MT_143': StandardScaler(),\n",
       " 'MT_144': StandardScaler(),\n",
       " 'MT_145': StandardScaler(),\n",
       " 'MT_146': StandardScaler(),\n",
       " 'MT_147': StandardScaler(),\n",
       " 'MT_148': StandardScaler(),\n",
       " 'MT_149': StandardScaler(),\n",
       " 'MT_150': StandardScaler(),\n",
       " 'MT_151': StandardScaler(),\n",
       " 'MT_152': StandardScaler(),\n",
       " 'MT_153': StandardScaler(),\n",
       " 'MT_154': StandardScaler(),\n",
       " 'MT_155': StandardScaler(),\n",
       " 'MT_156': StandardScaler(),\n",
       " 'MT_157': StandardScaler(),\n",
       " 'MT_158': StandardScaler(),\n",
       " 'MT_159': StandardScaler(),\n",
       " 'MT_160': StandardScaler(),\n",
       " 'MT_161': StandardScaler(),\n",
       " 'MT_162': StandardScaler(),\n",
       " 'MT_163': StandardScaler(),\n",
       " 'MT_164': StandardScaler(),\n",
       " 'MT_165': StandardScaler(),\n",
       " 'MT_166': StandardScaler(),\n",
       " 'MT_167': StandardScaler(),\n",
       " 'MT_168': StandardScaler(),\n",
       " 'MT_169': StandardScaler(),\n",
       " 'MT_170': StandardScaler(),\n",
       " 'MT_171': StandardScaler(),\n",
       " 'MT_172': StandardScaler(),\n",
       " 'MT_173': StandardScaler(),\n",
       " 'MT_174': StandardScaler(),\n",
       " 'MT_175': StandardScaler(),\n",
       " 'MT_176': StandardScaler(),\n",
       " 'MT_177': StandardScaler(),\n",
       " 'MT_178': StandardScaler(),\n",
       " 'MT_179': StandardScaler(),\n",
       " 'MT_180': StandardScaler(),\n",
       " 'MT_181': StandardScaler(),\n",
       " 'MT_182': StandardScaler(),\n",
       " 'MT_183': StandardScaler(),\n",
       " 'MT_184': StandardScaler(),\n",
       " 'MT_185': StandardScaler(),\n",
       " 'MT_186': StandardScaler(),\n",
       " 'MT_187': StandardScaler(),\n",
       " 'MT_188': StandardScaler(),\n",
       " 'MT_189': StandardScaler(),\n",
       " 'MT_190': StandardScaler(),\n",
       " 'MT_191': StandardScaler(),\n",
       " 'MT_192': StandardScaler(),\n",
       " 'MT_193': StandardScaler(),\n",
       " 'MT_194': StandardScaler(),\n",
       " 'MT_195': StandardScaler(),\n",
       " 'MT_196': StandardScaler(),\n",
       " 'MT_197': StandardScaler(),\n",
       " 'MT_198': StandardScaler(),\n",
       " 'MT_199': StandardScaler(),\n",
       " 'MT_200': StandardScaler(),\n",
       " 'MT_201': StandardScaler(),\n",
       " 'MT_202': StandardScaler(),\n",
       " 'MT_203': StandardScaler(),\n",
       " 'MT_204': StandardScaler(),\n",
       " 'MT_205': StandardScaler(),\n",
       " 'MT_206': StandardScaler(),\n",
       " 'MT_207': StandardScaler(),\n",
       " 'MT_208': StandardScaler(),\n",
       " 'MT_209': StandardScaler(),\n",
       " 'MT_210': StandardScaler(),\n",
       " 'MT_211': StandardScaler(),\n",
       " 'MT_212': StandardScaler(),\n",
       " 'MT_213': StandardScaler(),\n",
       " 'MT_214': StandardScaler(),\n",
       " 'MT_215': StandardScaler(),\n",
       " 'MT_216': StandardScaler(),\n",
       " 'MT_217': StandardScaler(),\n",
       " 'MT_218': StandardScaler(),\n",
       " 'MT_219': StandardScaler(),\n",
       " 'MT_220': StandardScaler(),\n",
       " 'MT_221': StandardScaler(),\n",
       " 'MT_222': StandardScaler(),\n",
       " 'MT_224': StandardScaler(),\n",
       " 'MT_225': StandardScaler(),\n",
       " 'MT_226': StandardScaler(),\n",
       " 'MT_227': StandardScaler(),\n",
       " 'MT_228': StandardScaler(),\n",
       " 'MT_229': StandardScaler(),\n",
       " 'MT_230': StandardScaler(),\n",
       " 'MT_231': StandardScaler(),\n",
       " 'MT_232': StandardScaler(),\n",
       " 'MT_233': StandardScaler(),\n",
       " 'MT_234': StandardScaler(),\n",
       " 'MT_235': StandardScaler(),\n",
       " 'MT_236': StandardScaler(),\n",
       " 'MT_237': StandardScaler(),\n",
       " 'MT_238': StandardScaler(),\n",
       " 'MT_239': StandardScaler(),\n",
       " 'MT_240': StandardScaler(),\n",
       " 'MT_241': StandardScaler(),\n",
       " 'MT_242': StandardScaler(),\n",
       " 'MT_243': StandardScaler(),\n",
       " 'MT_244': StandardScaler(),\n",
       " 'MT_245': StandardScaler(),\n",
       " 'MT_246': StandardScaler(),\n",
       " 'MT_247': StandardScaler(),\n",
       " 'MT_248': StandardScaler(),\n",
       " 'MT_249': StandardScaler(),\n",
       " 'MT_250': StandardScaler(),\n",
       " 'MT_251': StandardScaler(),\n",
       " 'MT_252': StandardScaler(),\n",
       " 'MT_253': StandardScaler(),\n",
       " 'MT_254': StandardScaler(),\n",
       " 'MT_255': StandardScaler(),\n",
       " 'MT_256': StandardScaler(),\n",
       " 'MT_257': StandardScaler(),\n",
       " 'MT_258': StandardScaler(),\n",
       " 'MT_259': StandardScaler(),\n",
       " 'MT_260': StandardScaler(),\n",
       " 'MT_261': StandardScaler(),\n",
       " 'MT_262': StandardScaler(),\n",
       " 'MT_263': StandardScaler(),\n",
       " 'MT_264': StandardScaler(),\n",
       " 'MT_265': StandardScaler(),\n",
       " 'MT_266': StandardScaler(),\n",
       " 'MT_267': StandardScaler(),\n",
       " 'MT_268': StandardScaler(),\n",
       " 'MT_269': StandardScaler(),\n",
       " 'MT_270': StandardScaler(),\n",
       " 'MT_271': StandardScaler(),\n",
       " 'MT_272': StandardScaler(),\n",
       " 'MT_273': StandardScaler(),\n",
       " 'MT_274': StandardScaler(),\n",
       " 'MT_275': StandardScaler(),\n",
       " 'MT_276': StandardScaler(),\n",
       " 'MT_277': StandardScaler(),\n",
       " 'MT_278': StandardScaler(),\n",
       " 'MT_279': StandardScaler(),\n",
       " 'MT_280': StandardScaler(),\n",
       " 'MT_281': StandardScaler(),\n",
       " 'MT_282': StandardScaler(),\n",
       " 'MT_283': StandardScaler(),\n",
       " 'MT_284': StandardScaler(),\n",
       " 'MT_285': StandardScaler(),\n",
       " 'MT_286': StandardScaler(),\n",
       " 'MT_287': StandardScaler(),\n",
       " 'MT_288': StandardScaler(),\n",
       " 'MT_289': StandardScaler(),\n",
       " 'MT_290': StandardScaler(),\n",
       " 'MT_291': StandardScaler(),\n",
       " 'MT_292': StandardScaler(),\n",
       " 'MT_293': StandardScaler(),\n",
       " 'MT_294': StandardScaler(),\n",
       " 'MT_295': StandardScaler(),\n",
       " 'MT_296': StandardScaler(),\n",
       " 'MT_297': StandardScaler(),\n",
       " 'MT_298': StandardScaler(),\n",
       " 'MT_299': StandardScaler(),\n",
       " 'MT_300': StandardScaler(),\n",
       " 'MT_301': StandardScaler(),\n",
       " 'MT_302': StandardScaler(),\n",
       " 'MT_303': StandardScaler(),\n",
       " 'MT_304': StandardScaler(),\n",
       " 'MT_305': StandardScaler(),\n",
       " 'MT_306': StandardScaler(),\n",
       " 'MT_307': StandardScaler(),\n",
       " 'MT_308': StandardScaler(),\n",
       " 'MT_309': StandardScaler(),\n",
       " 'MT_310': StandardScaler(),\n",
       " 'MT_311': StandardScaler(),\n",
       " 'MT_312': StandardScaler(),\n",
       " 'MT_313': StandardScaler(),\n",
       " 'MT_314': StandardScaler(),\n",
       " 'MT_315': StandardScaler(),\n",
       " 'MT_316': StandardScaler(),\n",
       " 'MT_317': StandardScaler(),\n",
       " 'MT_318': StandardScaler(),\n",
       " 'MT_319': StandardScaler(),\n",
       " 'MT_320': StandardScaler(),\n",
       " 'MT_321': StandardScaler(),\n",
       " 'MT_322': StandardScaler(),\n",
       " 'MT_323': StandardScaler(),\n",
       " 'MT_324': StandardScaler(),\n",
       " 'MT_325': StandardScaler(),\n",
       " 'MT_326': StandardScaler(),\n",
       " 'MT_327': StandardScaler(),\n",
       " 'MT_328': StandardScaler(),\n",
       " 'MT_329': StandardScaler(),\n",
       " 'MT_330': StandardScaler(),\n",
       " 'MT_331': StandardScaler(),\n",
       " 'MT_332': StandardScaler(),\n",
       " 'MT_333': StandardScaler(),\n",
       " 'MT_334': StandardScaler(),\n",
       " 'MT_335': StandardScaler(),\n",
       " 'MT_336': StandardScaler(),\n",
       " 'MT_337': StandardScaler(),\n",
       " 'MT_338': StandardScaler(),\n",
       " 'MT_339': StandardScaler(),\n",
       " 'MT_340': StandardScaler(),\n",
       " 'MT_341': StandardScaler(),\n",
       " 'MT_342': StandardScaler(),\n",
       " 'MT_343': StandardScaler(),\n",
       " 'MT_344': StandardScaler(),\n",
       " 'MT_345': StandardScaler(),\n",
       " 'MT_346': StandardScaler(),\n",
       " 'MT_347': StandardScaler(),\n",
       " 'MT_348': StandardScaler(),\n",
       " 'MT_349': StandardScaler(),\n",
       " 'MT_350': StandardScaler(),\n",
       " 'MT_351': StandardScaler(),\n",
       " 'MT_352': StandardScaler(),\n",
       " 'MT_353': StandardScaler(),\n",
       " 'MT_354': StandardScaler(),\n",
       " 'MT_355': StandardScaler(),\n",
       " 'MT_356': StandardScaler(),\n",
       " 'MT_357': StandardScaler(),\n",
       " 'MT_358': StandardScaler(),\n",
       " 'MT_359': StandardScaler(),\n",
       " 'MT_360': StandardScaler(),\n",
       " 'MT_361': StandardScaler(),\n",
       " 'MT_362': StandardScaler(),\n",
       " 'MT_363': StandardScaler(),\n",
       " 'MT_364': StandardScaler(),\n",
       " 'MT_365': StandardScaler(),\n",
       " 'MT_366': StandardScaler(),\n",
       " 'MT_367': StandardScaler(),\n",
       " 'MT_368': StandardScaler(),\n",
       " 'MT_369': StandardScaler(),\n",
       " 'MT_370': StandardScaler()}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_formatter._target_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'categorical_id': LabelEncoder()}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_formatter._cat_scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_cat_scalers',\n",
       " '_column_definition',\n",
       " '_get_input_columns',\n",
       " '_get_tft_input_indices',\n",
       " '_num_classes_per_cat_input',\n",
       " '_real_scalers',\n",
       " '_target_scaler',\n",
       " '_time_steps',\n",
       " 'format_predictions',\n",
       " 'get_column_definition',\n",
       " 'get_default_model_params',\n",
       " 'get_experiment_params',\n",
       " 'get_fixed_params',\n",
       " 'get_num_samples_for_calibration',\n",
       " 'identifiers',\n",
       " 'num_classes_per_cat_input',\n",
       " 'set_scalers',\n",
       " 'split_data',\n",
       " 'transform_inputs']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data_formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_usage</th>\n",
       "      <th>t</th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>categorical_id</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>hours_from_start</th>\n",
       "      <th>categorical_day_of_week</th>\n",
       "      <th>categorical_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17544</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26304.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26304.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17545</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26305.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26305.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17546</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26306.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 02:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26306.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17547</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26307.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 03:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26307.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17548</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26308.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2014-01-01 04:00:00</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26308.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10461482</th>\n",
       "      <td>20824.324324</td>\n",
       "      <td>32299.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>2014-09-07 19:00:00</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>32299.0</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10461483</th>\n",
       "      <td>19527.027027</td>\n",
       "      <td>32300.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>2014-09-07 20:00:00</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>32300.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10461484</th>\n",
       "      <td>20202.702703</td>\n",
       "      <td>32301.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>2014-09-07 21:00:00</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>32301.0</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10461485</th>\n",
       "      <td>19851.351351</td>\n",
       "      <td>32302.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>2014-09-07 22:00:00</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>32302.0</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10461486</th>\n",
       "      <td>20135.135135</td>\n",
       "      <td>32303.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>2014-09-07 23:00:00</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>32303.0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2198072 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           power_usage        t  days_from_start categorical_id  \\\n",
       "17544         2.538071  26304.0             1096         MT_001   \n",
       "17545         2.855330  26305.0             1096         MT_001   \n",
       "17546         2.855330  26306.0             1096         MT_001   \n",
       "17547         2.855330  26307.0             1096         MT_001   \n",
       "17548         2.538071  26308.0             1096         MT_001   \n",
       "...                ...      ...              ...            ...   \n",
       "10461482  20824.324324  32299.0             1345         MT_370   \n",
       "10461483  19527.027027  32300.0             1345         MT_370   \n",
       "10461484  20202.702703  32301.0             1345         MT_370   \n",
       "10461485  19851.351351  32302.0             1345         MT_370   \n",
       "10461486  20135.135135  32303.0             1345         MT_370   \n",
       "\n",
       "                         date      id  hour  day  day_of_week  month  \\\n",
       "17544     2014-01-01 00:00:00  MT_001     0    1            2      1   \n",
       "17545     2014-01-01 01:00:00  MT_001     1    1            2      1   \n",
       "17546     2014-01-01 02:00:00  MT_001     2    1            2      1   \n",
       "17547     2014-01-01 03:00:00  MT_001     3    1            2      1   \n",
       "17548     2014-01-01 04:00:00  MT_001     4    1            2      1   \n",
       "...                       ...     ...   ...  ...          ...    ...   \n",
       "10461482  2014-09-07 19:00:00  MT_370    19    7            6      9   \n",
       "10461483  2014-09-07 20:00:00  MT_370    20    7            6      9   \n",
       "10461484  2014-09-07 21:00:00  MT_370    21    7            6      9   \n",
       "10461485  2014-09-07 22:00:00  MT_370    22    7            6      9   \n",
       "10461486  2014-09-07 23:00:00  MT_370    23    7            6      9   \n",
       "\n",
       "          hours_from_start  categorical_day_of_week  categorical_hour  \n",
       "17544              26304.0                        2                 0  \n",
       "17545              26305.0                        2                 1  \n",
       "17546              26306.0                        2                 2  \n",
       "17547              26307.0                        2                 3  \n",
       "17548              26308.0                        2                 4  \n",
       "...                    ...                      ...               ...  \n",
       "10461482           32299.0                        6                19  \n",
       "10461483           32300.0                        6                20  \n",
       "10461484           32301.0                        6                21  \n",
       "10461485           32302.0                        6                22  \n",
       "10461486           32303.0                        6                23  \n",
       "\n",
       "[2198072 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_time_steps': 192,\n",
       " 'num_encoder_steps': 168,\n",
       " 'num_epochs': 100,\n",
       " 'early_stopping_patience': 5,\n",
       " 'multiprocessing_workers': 5,\n",
       " 'column_definition': [('id', <DataTypes.REAL_VALUED: 0>, <InputTypes.ID: 4>),\n",
       "  ('hours_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.TIME: 5>),\n",
       "  ('power_usage', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>),\n",
       "  ('hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>),\n",
       "  ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>),\n",
       "  ('hours_from_start',\n",
       "   <DataTypes.REAL_VALUED: 0>,\n",
       "   <InputTypes.KNOWN_INPUT: 2>),\n",
       "  ('categorical_id',\n",
       "   <DataTypes.CATEGORICAL: 1>,\n",
       "   <InputTypes.STATIC_INPUT: 3>)],\n",
       " 'input_size': 5,\n",
       " 'output_size': 1,\n",
       " 'category_counts': [369],\n",
       " 'input_obs_loc': [0],\n",
       " 'static_input_loc': [4],\n",
       " 'known_regular_inputs': [1, 2, 3],\n",
       " 'known_categorical_inputs': [],\n",
       " 'dropout_rate': 0.1,\n",
       " 'hidden_layer_size': 160,\n",
       " 'learning_rate': 0.001,\n",
       " 'minibatch_size': 64,\n",
       " 'max_gradient_norm': 0.01,\n",
       " 'num_heads': 4,\n",
       " 'stack_size': 1,\n",
       " 'batch_first': True,\n",
       " 'name': 'test',\n",
       " 'device': 'cpu',\n",
       " 'quantiles': [0.5]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting valid sampling locations.\n",
      "# available segments=1853057\n",
      "Extracting 256 samples...\n"
     ]
    }
   ],
   "source": [
    "max_samples = 256  #* 200 * 2\n",
    "elect = ts_dataset.TSDataset(fixed_params, max_samples, train)\n",
    "\n",
    "# with open('ts_dataset_m4.pkl', 'wb') as output:  # Overwrites any existing file.\n",
    "#     pickle.dump(elect, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('ts_dataset_m4.pkl', 'rb') as input:\n",
    "#     elect = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "            elect,\n",
    "            batch_size=fixed_params['minibatch_size'],\n",
    "            num_workers=2,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_time_steps': 192, 'num_encoder_steps': 168, 'num_epochs': 100, 'early_stopping_patience': 5, 'multiprocessing_workers': 5, 'column_definition': [('id', <DataTypes.REAL_VALUED: 0>, <InputTypes.ID: 4>), ('hours_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.TIME: 5>), ('power_usage', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('hour', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('day_of_week', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('hours_from_start', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('categorical_id', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)], 'input_size': 5, 'output_size': 1, 'category_counts': [369], 'input_obs_loc': [0], 'static_input_loc': [4], 'known_regular_inputs': [1, 2, 3], 'known_categorical_inputs': [], 'dropout_rate': 0.1, 'hidden_layer_size': 160, 'learning_rate': 0.001, 'minibatch_size': 64, 'max_gradient_norm': 0.01, 'num_heads': 4, 'stack_size': 1, 'batch_first': True, 'name': 'test', 'device': 'cpu', 'quantiles': [0.5]}\n",
      "_known_regular_input_idx:[1, 2, 3], _known_categorical_input_idx:[], num_inputs:4\n",
      "num_categorical_variables\n",
      "1\n",
      "input_size:168, num_inputs:4, hidden_layer_size:160\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(tft_model)\n",
    "model = tft_model.TFT(fixed_params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses.quantile_loss import QuantileLoss\n",
    "from losses.smape_loss import SMAPELoss\n",
    "from losses.rmsse_loss import RMSSELoss\n",
    "from losses.pinball_loss import PinballLoss\n",
    "\n",
    "\n",
    "q_loss_func = RMSSELoss(fixed_params['device'])\n",
    "# q_loss_func = SMAPELoss(fixed_params['device'])\n",
    "# q_loss_func = QuantileLoss(fixed_params['quantiles'])\n",
    "# import sys\n",
    "# sys.path.append('/home/arda/Desktop/thesis/')\n",
    "# from loss_modules import PinballLoss\n",
    "q_loss_func = PinballLoss(0.45, device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFT(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(369, 160)\n",
       "  )\n",
       "  (static_input_layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "  (time_varying_embedding_layer): LinearLayer(\n",
       "    (layer): TimeDistributed(\n",
       "      (module): Linear(in_features=1, out_features=160, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (static_combine_and_mask): StaticCombineAndMask(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (linear_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=1, bias=True)\n",
       "      )\n",
       "      (hidden_linear_layer1): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (hidden_context_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (hidden_linear_layer2): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (elu1): ELU(alpha=1.0)\n",
       "      (glu): GLU(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "        (gated_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (add_and_norm): AddAndNorm(\n",
       "        (normalize): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (static_context_variable_selection_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_enrichment_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_state_h_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_state_c_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (historical_lstm_combine_and_mask): LSTMCombineAndMask(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (linear_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=640, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer1): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=640, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_context_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer2): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (elu1): ELU(alpha=1.0)\n",
       "      (glu): GLU(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (gated_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (add_and_norm): AddAndNorm(\n",
       "        (normalize): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=2)\n",
       "  )\n",
       "  (future_lstm_combine_and_mask): LSTMCombineAndMask(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (linear_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=480, out_features=3, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer1): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=480, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_context_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer2): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (elu1): ELU(alpha=1.0)\n",
       "      (glu): GLU(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=3, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (gated_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=3, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (add_and_norm): AddAndNorm(\n",
       "        (normalize): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (2): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=2)\n",
       "  )\n",
       "  (lstm_encoder): LSTM(160, 160, batch_first=True)\n",
       "  (lstm_decoder): LSTM(160, 160, batch_first=True)\n",
       "  (lstm_glu): GLU(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gated_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (lstm_glu_add_and_norm): AddAndNorm(\n",
       "    (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (static_enrichment_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (self_attn_layer): InterpretableMultiHeadAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (qs_layers): ModuleList(\n",
       "      (0): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (1): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (2): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (3): Linear(in_features=160, out_features=40, bias=False)\n",
       "    )\n",
       "    (ks_layers): ModuleList(\n",
       "      (0): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (1): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (2): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (3): Linear(in_features=160, out_features=40, bias=False)\n",
       "    )\n",
       "    (vs_layers): ModuleList(\n",
       "      (0): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (1): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (2): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (3): Linear(in_features=160, out_features=40, bias=False)\n",
       "    )\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (activation): Softmax(dim=-1)\n",
       "    )\n",
       "    (w_o): Linear(in_features=40, out_features=160, bias=False)\n",
       "  )\n",
       "  (self_attention_glu): GLU(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gated_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (self_attention_glu_add_and_norm): AddAndNorm(\n",
       "    (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (final_glu): GLU(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gated_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (final_glu_add_and_norm): AddAndNorm(\n",
       "    (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_layer): LinearLayer(\n",
       "    (layer): TimeDistributed(\n",
       "      (module): Linear(in_features=160, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:02<00:07,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:05<00:05,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:17<00:07,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:20<00:00,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4982758238911629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:02<00:07,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:05<00:05,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:07<00:02,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4814930036664009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:02<00:08,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:05<00:05,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:07<00:02,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4634839668869972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:02<00:07,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:05<00:05,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:07<00:02,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4671187773346901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:02<00:07,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:04<00:04,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:07<00:02,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42798563092947006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epochs=5\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    epoch_loss = [] \n",
    "    progress_bar = tqdm(enumerate(loader), total=len(loader))\n",
    "    for batch_num, batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        output, all_inputs, attention_components = model(batch['inputs'])\n",
    "#         loss= q_loss_func(output[:,:,:].view(-1,1), batch['outputs'][:,:,0].flatten().float().to(device))\n",
    "        loss = q_loss_func(output.squeeze(2), batch['outputs'][:,:,0].float().to(device))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), fixed_params['max_gradient_norm'])\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    \n",
    "    losses.append(np.mean(epoch_loss))\n",
    "    if loss.item() <= min(losses):\n",
    "        torch.save(model.state_dict(), 'electricity_best_model_smape_loss.pth')\n",
    "        \n",
    "    print(np.mean(epoch_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test():\n",
    "    max_samples = 1000\n",
    "    test_elect = ts_dataset.TSDataset(fixed_params, max_samples, test)\n",
    "    loader = DataLoader(\n",
    "            test_elect,\n",
    "            batch_size=fixed_params['minibatch_size'],\n",
    "            num_workers=2,\n",
    "            shuffle=False\n",
    "        )\n",
    "    \n",
    "    total_outputs = []\n",
    "    total_ids = []\n",
    "    total_times = []\n",
    "    for batch in loader:\n",
    "        test_inputs = batch[\"inputs\"]\n",
    "        test_outputs = batch[\"outputs\"]\n",
    "        active_entries = batch[\"active_entries\"]\n",
    "        time = batch[\"time\"]\n",
    "        identifier = batch[\"identifier\"]\n",
    "        \n",
    "        output, all_inputs, attention_components = model(test_inputs)\n",
    "        total_outputs.append(output)\n",
    "        total_ids.append(identifier)\n",
    "        total_times.append(time)\n",
    "    return total_ids, total_times, total_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting valid sampling locations.\n",
      "# available segments=53505\n",
      "Extracting 1000 samples...\n",
      "1000 of 1000 samples done...\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([64, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([64, 192, 160, 3]), obs_inputs:torch.Size([64, 192, 160, 1]), static_inputs:torch.Size([64, 1, 160])\n",
      "historical_inputs:torch.Size([64, 168, 160, 4]), future_inputs:torch.Size([64, 24, 160, 3])\n",
      "all_inputs:torch.Size([40, 192, 5]), unknown_inputs:None, known_combined_layer:torch.Size([40, 192, 160, 3]), obs_inputs:torch.Size([40, 192, 160, 1]), static_inputs:torch.Size([40, 1, 160])\n",
      "historical_inputs:torch.Size([40, 168, 160, 4]), future_inputs:torch.Size([40, 24, 160, 3])\n"
     ]
    }
   ],
   "source": [
    "test_ids, test_times, test_outputs = eval_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 24, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, torch.Size([64, 24, 1]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ids[0]), test_outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids, test_times, test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123984, 13)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TSDataset' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0ff999c1dff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_elect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TSDataset' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "test_elect.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting valid sampling locations.\n",
      "# available segments=53505\n",
      "Extracting 256 samples...\n"
     ]
    }
   ],
   "source": [
    "## 测试集的model结果\n",
    "test_elect = ts_dataset.TSDataset(fixed_params, max_samples, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = next(iter(test_elect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t1[\"identifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192, 5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[\"inputs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series\n",
    "pred = Series(output[ind,:,0].detach().cpu().numpy())\n",
    "label = Series(batch['outputs'][ind,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24.000000\n",
       "mean     -0.420291\n",
       "std       0.400840\n",
       "min      -1.109453\n",
       "25%      -0.753975\n",
       "50%      -0.244248\n",
       "75%      -0.118187\n",
       "max       0.075995\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7faa4c9530d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ind = np.random.choice(64)\n",
    "print(ind)\n",
    "plt.plot(output[ind,:,0].detach().cpu().numpy(), label='pred_1')\n",
    "# plt.plot(output[ind,:,1].detach().cpu().numpy(), label='pred_5')\n",
    "# plt.plot(output[ind,:,2].detach().cpu().numpy(), label='pred_9')\n",
    "\n",
    "plt.plot(batch['outputs'][ind,:,0], label='true')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(forecast, actual):\n",
    "    # Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    sequence_length = forecast.shape[1]\n",
    "    sumf = np.sum(np.abs(forecast - actual) / (np.abs(actual) + np.abs(forecast)), axis=1)\n",
    "    return np.mean((2 * sumf) / sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5027896522704651"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetric_mean_absolute_percentage_error(output[:,:,0].detach().cpu().numpy(),\n",
    "                                        batch['outputs'][:,:,0].detach().cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
