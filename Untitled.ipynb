{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,Dataset, Subset\n",
    "import numpy as np\n",
    "import tft_model\n",
    "from data_formatters import ts_dataset  \n",
    "import data_formatters.base\n",
    "import expt_settings.configs\n",
    "import importlib\n",
    "from data_formatters import utils\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "importlib.reload(tft_model)\n",
    "importlib.reload(utils)\n",
    "\n",
    "ExperimentConfig = expt_settings.configs.ExperimentConfig\n",
    "\n",
    "config = ExperimentConfig('m5', 'outputs')\n",
    "\n",
    "with open('data_formatter.pkl', 'rb') as input:\n",
    "    data_formatter = pickle.load(input)\n",
    "\n",
    "# data_formatter = config.make_data_formatter()\n",
    "#\n",
    "#\n",
    "# print(\"*** Training from defined parameters for {} ***\".format('m5'))\n",
    "# data_csv_path = '/home/arda/Desktop/thesis/m5_tft_data.csv'\n",
    "# print(\"Loading & splitting data...\")\n",
    "# raw_data = pd.read_csv(data_csv_path, index_col=0)\n",
    "# print(\"Data loaded...\")\n",
    "# train, valid, test = data_formatter.split_data(raw_data)\n",
    "# train_samples, valid_samples = data_formatter.get_num_samples_for_calibration()\n",
    "#\n",
    "# with open('train.pkl', 'wb') as output:  # Overwrites any existing file.\n",
    "#     pickle.dump(train, output, pickle.HIGHEST_PROTOCOL)\n",
    "#\n",
    "# with open('valid.pkl', 'wb') as output:  # Overwrites any existing file.\n",
    "#     pickle.dump(valid, output, pickle.HIGHEST_PROTOCOL)\n",
    "#\n",
    "# with open('test.pkl', 'wb') as output:  # Overwrites any existing file.\n",
    "#     pickle.dump(test, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Sets up default params\n",
    "fixed_params = data_formatter.get_experiment_params()\n",
    "params = data_formatter.get_default_model_params()\n",
    "\n",
    "# with open('data_formatter.pkl', 'wb') as output:  # Overwrites any existing file.\n",
    "#     pickle.dump(data_formatter, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "device = 'cpu' #torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "fixed_params.update(params)\n",
    "fixed_params['batch_first'] = True\n",
    "fixed_params['name'] = 'test'\n",
    "fixed_params['device'] = device\n",
    "fixed_params['minibatch_size'] = 128\n",
    "fixed_params['num_heads'] = 1\n",
    "\n",
    "max_samples = 512 * 10\n",
    "# ds = ts_dataset.TSDataset(fixed_params, max_samples, train)\n",
    "#\n",
    "# with open('ts_dataset.pkl', 'wb') as output:  # Overwrites any existing file.\n",
    "#     pickle.dump(ds, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('ts_dataset.pkl', 'rb') as input:\n",
    "    ds = pickle.load(input)\n",
    "\n",
    "batch_size=128\n",
    "loader = DataLoader(ds, batch_size=batch_size, num_workers=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in loader:\n",
    "    break\n",
    "#     print(batch['inputs'])\n",
    "# print(batch['inputs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_time_steps': 224, 'num_encoder_steps': 196, 'num_epochs': 100, 'early_stopping_patience': 5, 'multiprocessing_workers': 5, 'column_definition': [('id', <DataTypes.CATEGORICAL: 1>, <InputTypes.ID: 4>), ('date', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('quantity', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('sell_price', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('wday', <DataTypes.CATEGORICAL: 1>, <InputTypes.KNOWN_INPUT: 2>), ('month', <DataTypes.CATEGORICAL: 1>, <InputTypes.KNOWN_INPUT: 2>), ('year', <DataTypes.CATEGORICAL: 1>, <InputTypes.KNOWN_INPUT: 2>), ('store_id', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>), ('item_id', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>), ('dept_id', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>), ('cat_id', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>), ('state_id', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)], 'input_size': 10, 'output_size': 1, 'category_counts': [7, 12, 3, 10, 3049, 7, 3, 3], 'input_obs_loc': [0], 'static_input_loc': [5, 6, 7, 8, 9], 'known_regular_inputs': [1], 'known_categorical_inputs': [0, 1, 2, 3, 4, 5, 6, 7], 'dropout_rate': 0.3, 'hidden_layer_size': 160, 'learning_rate': 0.01, 'minibatch_size': 128, 'max_gradient_norm': 0.01, 'num_heads': 1, 'stack_size': 1, 'batch_first': True, 'name': 'test', 'device': 'cpu'}\n",
      "num_categorical_variables\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(tft_model)\n",
    "model = tft_model.TFT(fixed_params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6376,  0.3756,  0.6533,  ...,  0.7480,  0.9855,  1.2675],\n",
      "        [-0.2777, -0.4140, -1.1876,  ...,  1.1595,  0.5233, -0.9303],\n",
      "        [ 0.7000,  0.3253,  0.9814,  ..., -0.8203,  2.0331,  0.7670],\n",
      "        ...,\n",
      "        [-0.1126,  0.3939,  0.2961,  ...,  0.2579, -0.0203, -1.5872],\n",
      "        [-0.5271, -0.6724,  2.4753,  ...,  0.6853, -0.3379,  0.6787],\n",
      "        [-0.0909,  0.1346, -0.2122,  ..., -0.9259, -0.4700,  1.7699]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.6376,  0.3756,  0.6533,  ...,  0.7480,  0.9855,  1.2675],\n",
      "        [-0.2777, -0.4140, -1.1876,  ...,  1.1595,  0.5233, -0.9303],\n",
      "        [ 0.7000,  0.3253,  0.9814,  ..., -0.8203,  2.0331,  0.7670],\n",
      "        ...,\n",
      "        [-0.1126,  0.3939,  0.2961,  ...,  0.2579, -0.0203, -1.5872],\n",
      "        [-0.5271, -0.6724,  2.4753,  ...,  0.6853, -0.3379,  0.6787],\n",
      "        [-0.0909,  0.1346, -0.2122,  ..., -0.9259, -0.4700,  1.7699]],\n",
      "       requires_grad=True)\n",
      "output\n",
      "tensor([-0.4472, -0.1430,  0.3188], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:04<02:42,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], requires_grad=True)\n",
      "output\n",
      "tensor([nan, nan, nan], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d37ddbac8637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mq_loss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m#         torch.nn.utils.clip_grad_norm_(model.parameters(), fixed_params['max_gradient_norm'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/multiprocessing/process.py\", line 261, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/multiprocessing/util.py\", line 322, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/multiprocessing/util.py\", line 262, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/multiprocessing/util.py\", line 186, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/threading.py\", line 1056, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/multiprocessing/queues.py\", line 191, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/threading.py\", line 1056, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/arda/anaconda3/envs/thesis/lib/python3.6/threading.py\", line 1072, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "  2%|▎         | 1/40 [00:08<05:45,  8.87s/it]"
     ]
    }
   ],
   "source": [
    "# torch.save(loader, 'm5_dataloader.pth', pickle_protocol=4)\n",
    "\n",
    "\n",
    "\n",
    "q_loss_func = tft_model.QuantileLoss([0.1,0.5,0.9])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "epochs=100\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    epoch_loss = [] \n",
    "    progress_bar = tqdm(enumerate(loader), total=len(loader))\n",
    "    for batch_num, batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        output, all_inputs, attention_components = model(batch['inputs'])\n",
    "        print(\"output\")\n",
    "        print(output[0][0])\n",
    "        loss= q_loss_func(output[:,:,:].view(-1,3), batch['outputs'][:,:,0].flatten().float().to(device))\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), fixed_params['max_gradient_norm'])\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    \n",
    "    losses.append(np.mean(epoch_loss))\n",
    "    if loss.item() <= min(losses):\n",
    "        torch.save(model.state_dict(), 'm5_best_model.pth')\n",
    "        \n",
    "    print(np.mean(epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]]], device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
