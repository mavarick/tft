{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,Dataset, Subset\n",
    "import numpy as np\n",
    "import tft_model\n",
    "from data_formatters import ts_dataset  \n",
    "import data_formatters.base\n",
    "import expt_settings.configs\n",
    "import importlib\n",
    "from data_formatters import utils\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_formatters.utils' from '/home/arda/Desktop/thesis/submodules/Temporal_Fusion_Transform/data_formatters/utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentConfig = expt_settings.configs.ExperimentConfig\n",
    "\n",
    "config = ExperimentConfig('m4', 'outputs')\n",
    "\n",
    "with open('data_formatter_m4.pkl', 'rb') as input:\n",
    "    data_formatter = pickle.load(input)\n",
    "\n",
    "# Sets up default params\n",
    "fixed_params = data_formatter.get_experiment_params()\n",
    "params = data_formatter.get_default_model_params()\n",
    "\n",
    "fixed_params.update(params)\n",
    "fixed_params['batch_first'] = True\n",
    "fixed_params['name'] = 'test'\n",
    "fixed_params['device'] = 'cpu'# torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "fixed_params['minibatch_size'] = 256\n",
    "fixed_params['category_count'] = [6]\n",
    "device = fixed_params['device']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arda/anaconda3/envs/thesis/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/m4_test.csv', index_col=0)\n",
    "test_transformed_data = data_formatter.transform_inputs(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_time_steps': 54, 'num_encoder_steps': 36, 'num_epochs': 100, 'early_stopping_patience': 5, 'multiprocessing_workers': 5, 'column_definition': [('id', <DataTypes.CATEGORICAL: 1>, <InputTypes.ID: 4>), ('time', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('value', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('time_cat', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('category', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)], 'input_size': 3, 'output_size': 1, 'category_counts': [6], 'input_obs_loc': [0], 'static_input_loc': [2], 'known_regular_inputs': [1], 'known_categorical_inputs': [0], 'dropout_rate': 0.1, 'hidden_layer_size': 160, 'learning_rate': 0.001, 'minibatch_size': 256, 'max_gradient_norm': 0.01, 'num_heads': 4, 'stack_size': 1, 'batch_first': True, 'name': 'test', 'device': 'cpu', 'category_count': [6]}\n",
      "num_categorical_variables\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TFT(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(6, 160)\n",
       "  )\n",
       "  (static_input_layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "  (time_varying_embedding_layer): LinearLayer(\n",
       "    (layer): TimeDistributed(\n",
       "      (module): Linear(in_features=1, out_features=160, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (static_combine_and_mask): StaticCombineAndMask(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (linear_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=1, bias=True)\n",
       "      )\n",
       "      (hidden_linear_layer1): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (hidden_context_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (hidden_linear_layer2): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (elu1): ELU(alpha=1.0)\n",
       "      (glu): GLU(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "        (gated_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (add_and_norm): AddAndNorm(\n",
       "        (normalize): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (static_context_variable_selection_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_enrichment_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_state_h_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_state_c_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (historical_lstm_combine_and_mask): LSTMCombineAndMask(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (linear_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=320, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer1): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=320, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_context_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer2): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (elu1): ELU(alpha=1.0)\n",
       "      (glu): GLU(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (gated_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (add_and_norm): AddAndNorm(\n",
       "        (normalize): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=2)\n",
       "  )\n",
       "  (future_lstm_combine_and_mask): LSTMCombineAndMask(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (linear_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer1): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_context_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer2): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (elu1): ELU(alpha=1.0)\n",
       "      (glu): GLU(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (gated_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (add_and_norm): AddAndNorm(\n",
       "        (normalize): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=2)\n",
       "  )\n",
       "  (lstm_encoder): LSTM(160, 160, batch_first=True)\n",
       "  (lstm_decoder): LSTM(160, 160, batch_first=True)\n",
       "  (lstm_glu): GLU(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gated_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (lstm_glu_add_and_norm): AddAndNorm(\n",
       "    (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (static_enrichment_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (self_attn_layer): MultiheadAttention(\n",
       "    (out_proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "  )\n",
       "  (self_attention_glu): GLU(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gated_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (self_attention_glu_add_and_norm): AddAndNorm(\n",
       "    (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (final_glu): GLU(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gated_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (final_glu_add_and_norm): AddAndNorm(\n",
       "    (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_layer): LinearLayer(\n",
       "    (layer): TimeDistributed(\n",
       "      (module): Linear(in_features=160, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(tft_model)\n",
    "model = tft_model.TFT(fixed_params).to(device)\n",
    "model.load_state_dict(torch.load('m4_best_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting valid sampling locations.\n",
      "# available segments=48000\n",
      "Max samples=48000 exceeds # available segments=48000\n",
      "1000 of 48000 samples done...\n",
      "2000 of 48000 samples done...\n",
      "3000 of 48000 samples done...\n",
      "4000 of 48000 samples done...\n",
      "5000 of 48000 samples done...\n",
      "6000 of 48000 samples done...\n",
      "7000 of 48000 samples done...\n",
      "8000 of 48000 samples done...\n",
      "9000 of 48000 samples done...\n",
      "10000 of 48000 samples done...\n",
      "11000 of 48000 samples done...\n",
      "12000 of 48000 samples done...\n",
      "13000 of 48000 samples done...\n",
      "14000 of 48000 samples done...\n",
      "15000 of 48000 samples done...\n",
      "16000 of 48000 samples done...\n",
      "17000 of 48000 samples done...\n",
      "18000 of 48000 samples done...\n",
      "19000 of 48000 samples done...\n",
      "20000 of 48000 samples done...\n",
      "21000 of 48000 samples done...\n",
      "22000 of 48000 samples done...\n",
      "23000 of 48000 samples done...\n",
      "24000 of 48000 samples done...\n",
      "25000 of 48000 samples done...\n",
      "26000 of 48000 samples done...\n",
      "27000 of 48000 samples done...\n",
      "28000 of 48000 samples done...\n",
      "29000 of 48000 samples done...\n",
      "30000 of 48000 samples done...\n",
      "31000 of 48000 samples done...\n",
      "32000 of 48000 samples done...\n",
      "33000 of 48000 samples done...\n",
      "34000 of 48000 samples done...\n",
      "35000 of 48000 samples done...\n",
      "36000 of 48000 samples done...\n",
      "37000 of 48000 samples done...\n",
      "38000 of 48000 samples done...\n",
      "39000 of 48000 samples done...\n",
      "40000 of 48000 samples done...\n",
      "41000 of 48000 samples done...\n",
      "42000 of 48000 samples done...\n",
      "43000 of 48000 samples done...\n",
      "44000 of 48000 samples done...\n",
      "45000 of 48000 samples done...\n",
      "46000 of 48000 samples done...\n",
      "47000 of 48000 samples done...\n",
      "48000 of 48000 samples done...\n"
     ]
    }
   ],
   "source": [
    "test_ds = ts_dataset.TSDataset(fixed_params, 48000, test_transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "            test_ds,\n",
    "            batch_size=fixed_params['minibatch_size'],\n",
    "            num_workers=2,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_forecasts = []\n",
    "truth = []\n",
    "dfs = []\n",
    "for idx, batch in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output, all_inputs, attention_components = model(batch['inputs'])\n",
    "        flat_prediction = pd.DataFrame(\n",
    "          output.detach().cpu().numpy()[:, :, 1],\n",
    "          columns=[\n",
    "              't+{}'.format(i)\n",
    "              for i in range(18)\n",
    "          ])\n",
    "        cols = list(flat_prediction.columns)\n",
    "#         flat_prediction['forecast_time'] = batch['time'][:, 54 - 1, 0]\n",
    "        flat_prediction['identifier'] = batch['identifier'][0][0].detach().cpu().numpy()\n",
    "        dfs.append(flat_prediction)\n",
    "#         df = pd.DataFrame({\n",
    "#             'id': batch['identifier'][0][0].detach().cpu().numpy(),\n",
    "#             'time': batch['time'][0][0].detach().cpu().numpy(),\n",
    "# #             'output': output[:,:,1].detach().cpu().numpy(),\n",
    "#             'category': batch['inputs'][:,:18,2].detach().cpu().numpy(),\n",
    "#             'time_cat': batch['inputs'][:,:18,1].detach().cpu().numpy(),\n",
    "            \n",
    "#         })\n",
    "#         print(batch['time'])\n",
    "#         print(batch['identifier'])\n",
    "#         dfs.append(df)\n",
    "#         a = output[:,:,1].detach().cpu().numpy()\n",
    "#         final_forecasts.append(a)\n",
    "#         truth.append(batch['outputs'])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_unnormalized = data_formatter.format_predictions(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t+0</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t+7</th>\n",
       "      <th>t+8</th>\n",
       "      <th>t+9</th>\n",
       "      <th>t+10</th>\n",
       "      <th>t+11</th>\n",
       "      <th>t+12</th>\n",
       "      <th>t+13</th>\n",
       "      <th>t+14</th>\n",
       "      <th>t+15</th>\n",
       "      <th>t+16</th>\n",
       "      <th>t+17</th>\n",
       "      <th>identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8063.508789</td>\n",
       "      <td>7104.067871</td>\n",
       "      <td>6030.321777</td>\n",
       "      <td>5992.728516</td>\n",
       "      <td>5604.426758</td>\n",
       "      <td>5418.181152</td>\n",
       "      <td>5526.663086</td>\n",
       "      <td>5250.806641</td>\n",
       "      <td>5165.821289</td>\n",
       "      <td>4997.172363</td>\n",
       "      <td>5150.249512</td>\n",
       "      <td>6497.036133</td>\n",
       "      <td>7580.217773</td>\n",
       "      <td>6948.403809</td>\n",
       "      <td>6177.092773</td>\n",
       "      <td>6301.488281</td>\n",
       "      <td>5945.148926</td>\n",
       "      <td>5785.756836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2519.071045</td>\n",
       "      <td>2040.673096</td>\n",
       "      <td>2041.571045</td>\n",
       "      <td>1880.919556</td>\n",
       "      <td>1825.895264</td>\n",
       "      <td>1832.087402</td>\n",
       "      <td>1980.114502</td>\n",
       "      <td>1954.800293</td>\n",
       "      <td>1932.448730</td>\n",
       "      <td>1810.577148</td>\n",
       "      <td>1860.679443</td>\n",
       "      <td>2475.611572</td>\n",
       "      <td>2603.227539</td>\n",
       "      <td>2180.435303</td>\n",
       "      <td>2201.615967</td>\n",
       "      <td>2007.540527</td>\n",
       "      <td>1897.187866</td>\n",
       "      <td>1877.701294</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13108.545898</td>\n",
       "      <td>13120.634766</td>\n",
       "      <td>13177.564453</td>\n",
       "      <td>13227.753906</td>\n",
       "      <td>13268.650391</td>\n",
       "      <td>13283.268555</td>\n",
       "      <td>13267.883789</td>\n",
       "      <td>13233.587891</td>\n",
       "      <td>13189.882812</td>\n",
       "      <td>13143.978516</td>\n",
       "      <td>13104.396484</td>\n",
       "      <td>13078.715820</td>\n",
       "      <td>13068.772461</td>\n",
       "      <td>13072.294922</td>\n",
       "      <td>13081.875977</td>\n",
       "      <td>13081.304688</td>\n",
       "      <td>13059.160156</td>\n",
       "      <td>13031.944336</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6584.670410</td>\n",
       "      <td>6574.578125</td>\n",
       "      <td>6566.540039</td>\n",
       "      <td>6563.057617</td>\n",
       "      <td>6560.179688</td>\n",
       "      <td>6557.083984</td>\n",
       "      <td>6555.025391</td>\n",
       "      <td>6554.160645</td>\n",
       "      <td>6554.003906</td>\n",
       "      <td>6554.509766</td>\n",
       "      <td>6555.809082</td>\n",
       "      <td>6557.825195</td>\n",
       "      <td>6560.390137</td>\n",
       "      <td>6563.455078</td>\n",
       "      <td>6567.062988</td>\n",
       "      <td>6571.225098</td>\n",
       "      <td>6575.915039</td>\n",
       "      <td>6581.044922</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4351.281738</td>\n",
       "      <td>4362.601074</td>\n",
       "      <td>4372.187500</td>\n",
       "      <td>4379.628906</td>\n",
       "      <td>4382.774414</td>\n",
       "      <td>4382.413086</td>\n",
       "      <td>4381.326172</td>\n",
       "      <td>4381.081543</td>\n",
       "      <td>4382.101562</td>\n",
       "      <td>4384.914551</td>\n",
       "      <td>4390.341797</td>\n",
       "      <td>4398.632324</td>\n",
       "      <td>4408.666016</td>\n",
       "      <td>4418.626465</td>\n",
       "      <td>4427.214355</td>\n",
       "      <td>4433.960449</td>\n",
       "      <td>4438.873047</td>\n",
       "      <td>4442.321289</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4512.383301</td>\n",
       "      <td>5587.625488</td>\n",
       "      <td>6425.193359</td>\n",
       "      <td>6700.274902</td>\n",
       "      <td>6519.763184</td>\n",
       "      <td>3768.680176</td>\n",
       "      <td>4391.386719</td>\n",
       "      <td>4535.007324</td>\n",
       "      <td>4796.701172</td>\n",
       "      <td>5340.576172</td>\n",
       "      <td>4793.538086</td>\n",
       "      <td>4251.613770</td>\n",
       "      <td>4303.494141</td>\n",
       "      <td>5564.003906</td>\n",
       "      <td>6332.891602</td>\n",
       "      <td>6639.011719</td>\n",
       "      <td>6564.480469</td>\n",
       "      <td>4124.822754</td>\n",
       "      <td>47996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1047.017578</td>\n",
       "      <td>1040.422119</td>\n",
       "      <td>1020.738708</td>\n",
       "      <td>999.059265</td>\n",
       "      <td>953.195862</td>\n",
       "      <td>936.185913</td>\n",
       "      <td>942.184021</td>\n",
       "      <td>964.075439</td>\n",
       "      <td>1022.250732</td>\n",
       "      <td>1076.291016</td>\n",
       "      <td>1108.979370</td>\n",
       "      <td>1130.048706</td>\n",
       "      <td>1144.845581</td>\n",
       "      <td>1158.240723</td>\n",
       "      <td>1164.844727</td>\n",
       "      <td>1160.739014</td>\n",
       "      <td>1153.642822</td>\n",
       "      <td>1149.594482</td>\n",
       "      <td>47997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5130.028809</td>\n",
       "      <td>5183.496582</td>\n",
       "      <td>5223.339355</td>\n",
       "      <td>5179.468750</td>\n",
       "      <td>5205.994629</td>\n",
       "      <td>5227.942383</td>\n",
       "      <td>5230.349609</td>\n",
       "      <td>5231.232422</td>\n",
       "      <td>5236.319824</td>\n",
       "      <td>5245.101074</td>\n",
       "      <td>5256.240723</td>\n",
       "      <td>5270.093750</td>\n",
       "      <td>5286.376465</td>\n",
       "      <td>5302.825684</td>\n",
       "      <td>5319.274902</td>\n",
       "      <td>5338.595703</td>\n",
       "      <td>5361.318848</td>\n",
       "      <td>5386.355469</td>\n",
       "      <td>47998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>4543.601074</td>\n",
       "      <td>4571.569824</td>\n",
       "      <td>4564.506836</td>\n",
       "      <td>4568.473633</td>\n",
       "      <td>4586.417480</td>\n",
       "      <td>4577.458984</td>\n",
       "      <td>4568.199707</td>\n",
       "      <td>4593.035156</td>\n",
       "      <td>4601.523438</td>\n",
       "      <td>4605.158691</td>\n",
       "      <td>4639.278320</td>\n",
       "      <td>4630.979004</td>\n",
       "      <td>4627.535645</td>\n",
       "      <td>4651.303711</td>\n",
       "      <td>4621.646973</td>\n",
       "      <td>4608.880371</td>\n",
       "      <td>4609.382812</td>\n",
       "      <td>4596.648926</td>\n",
       "      <td>47999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5241.562012</td>\n",
       "      <td>5263.301758</td>\n",
       "      <td>5267.427246</td>\n",
       "      <td>5258.485840</td>\n",
       "      <td>5254.330566</td>\n",
       "      <td>5240.702637</td>\n",
       "      <td>5236.421875</td>\n",
       "      <td>5239.042969</td>\n",
       "      <td>5246.854004</td>\n",
       "      <td>5257.832031</td>\n",
       "      <td>5271.103027</td>\n",
       "      <td>5287.762695</td>\n",
       "      <td>5306.063477</td>\n",
       "      <td>5322.620117</td>\n",
       "      <td>5335.353027</td>\n",
       "      <td>5343.631836</td>\n",
       "      <td>5347.539551</td>\n",
       "      <td>5347.634277</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48000 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              t+0           t+1           t+2           t+3           t+4  \\\n",
       "0     8063.508789   7104.067871   6030.321777   5992.728516   5604.426758   \n",
       "1     2519.071045   2040.673096   2041.571045   1880.919556   1825.895264   \n",
       "2    13108.545898  13120.634766  13177.564453  13227.753906  13268.650391   \n",
       "3     6584.670410   6574.578125   6566.540039   6563.057617   6560.179688   \n",
       "4     4351.281738   4362.601074   4372.187500   4379.628906   4382.774414   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "123   4512.383301   5587.625488   6425.193359   6700.274902   6519.763184   \n",
       "124   1047.017578   1040.422119   1020.738708    999.059265    953.195862   \n",
       "125   5130.028809   5183.496582   5223.339355   5179.468750   5205.994629   \n",
       "126   4543.601074   4571.569824   4564.506836   4568.473633   4586.417480   \n",
       "127   5241.562012   5263.301758   5267.427246   5258.485840   5254.330566   \n",
       "\n",
       "              t+5           t+6           t+7           t+8           t+9  \\\n",
       "0     5418.181152   5526.663086   5250.806641   5165.821289   4997.172363   \n",
       "1     1832.087402   1980.114502   1954.800293   1932.448730   1810.577148   \n",
       "2    13283.268555  13267.883789  13233.587891  13189.882812  13143.978516   \n",
       "3     6557.083984   6555.025391   6554.160645   6554.003906   6554.509766   \n",
       "4     4382.413086   4381.326172   4381.081543   4382.101562   4384.914551   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "123   3768.680176   4391.386719   4535.007324   4796.701172   5340.576172   \n",
       "124    936.185913    942.184021    964.075439   1022.250732   1076.291016   \n",
       "125   5227.942383   5230.349609   5231.232422   5236.319824   5245.101074   \n",
       "126   4577.458984   4568.199707   4593.035156   4601.523438   4605.158691   \n",
       "127   5240.702637   5236.421875   5239.042969   5246.854004   5257.832031   \n",
       "\n",
       "             t+10          t+11          t+12          t+13          t+14  \\\n",
       "0     5150.249512   6497.036133   7580.217773   6948.403809   6177.092773   \n",
       "1     1860.679443   2475.611572   2603.227539   2180.435303   2201.615967   \n",
       "2    13104.396484  13078.715820  13068.772461  13072.294922  13081.875977   \n",
       "3     6555.809082   6557.825195   6560.390137   6563.455078   6567.062988   \n",
       "4     4390.341797   4398.632324   4408.666016   4418.626465   4427.214355   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "123   4793.538086   4251.613770   4303.494141   5564.003906   6332.891602   \n",
       "124   1108.979370   1130.048706   1144.845581   1158.240723   1164.844727   \n",
       "125   5256.240723   5270.093750   5286.376465   5302.825684   5319.274902   \n",
       "126   4639.278320   4630.979004   4627.535645   4651.303711   4621.646973   \n",
       "127   5271.103027   5287.762695   5306.063477   5322.620117   5335.353027   \n",
       "\n",
       "             t+15          t+16          t+17  identifier  \n",
       "0     6301.488281   5945.148926   5785.756836           1  \n",
       "1     2007.540527   1897.187866   1877.701294           2  \n",
       "2    13081.304688  13059.160156  13031.944336           3  \n",
       "3     6571.225098   6575.915039   6581.044922           4  \n",
       "4     4433.960449   4438.873047   4442.321289           5  \n",
       "..            ...           ...           ...         ...  \n",
       "123   6639.011719   6564.480469   4124.822754       47996  \n",
       "124   1160.739014   1153.642822   1149.594482       47997  \n",
       "125   5338.595703   5361.318848   5386.355469       47998  \n",
       "126   4608.880371   4609.382812   4596.648926       47999  \n",
       "127   5343.631836   5347.539551   5347.634277       48000  \n",
       "\n",
       "[48000 rows x 19 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions_unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(forecast, actual):\n",
    "    # Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    return np.mean(2 * np.abs(forecast - actual) / (np.abs(actual) + np.abs(forecast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = pd.read_csv('/home/arda/Desktop/thesis/datasets/m4/Test/Monthly-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(actuals.drop(columns=['V1']).values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(all_predictions_unnormalized.drop(columns=['identifier']).values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1473843219611202"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetric_mean_absolute_percentage_error(np.concatenate(all_predictions_unnormalized.drop(columns=['identifier']).values) ,np.concatenate(actuals.drop(columns=['V1']).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "      <th>category</th>\n",
       "      <th>time_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2118918</th>\n",
       "      <td>17144</td>\n",
       "      <td>2812</td>\n",
       "      <td>1085.036158</td>\n",
       "      <td>Micro</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118917</th>\n",
       "      <td>17144</td>\n",
       "      <td>2811</td>\n",
       "      <td>1088.157304</td>\n",
       "      <td>Micro</td>\n",
       "      <td>2811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118916</th>\n",
       "      <td>17144</td>\n",
       "      <td>2810</td>\n",
       "      <td>1091.318412</td>\n",
       "      <td>Micro</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118915</th>\n",
       "      <td>17144</td>\n",
       "      <td>2809</td>\n",
       "      <td>1102.066864</td>\n",
       "      <td>Micro</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118914</th>\n",
       "      <td>17144</td>\n",
       "      <td>2808</td>\n",
       "      <td>1113.808746</td>\n",
       "      <td>Micro</td>\n",
       "      <td>2808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037151</th>\n",
       "      <td>47812</td>\n",
       "      <td>8</td>\n",
       "      <td>8677.300000</td>\n",
       "      <td>Other</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037024</th>\n",
       "      <td>47810</td>\n",
       "      <td>8</td>\n",
       "      <td>7311.100000</td>\n",
       "      <td>Other</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10043898</th>\n",
       "      <td>47861</td>\n",
       "      <td>8</td>\n",
       "      <td>4566.390000</td>\n",
       "      <td>Other</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10043897</th>\n",
       "      <td>47861</td>\n",
       "      <td>7</td>\n",
       "      <td>4860.620000</td>\n",
       "      <td>Other</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042785</th>\n",
       "      <td>47853</td>\n",
       "      <td>7</td>\n",
       "      <td>4913.680000</td>\n",
       "      <td>Other</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2592000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  time        value category  time_cat\n",
       "2118918   17144  2812  1085.036158    Micro      2812\n",
       "2118917   17144  2811  1088.157304    Micro      2811\n",
       "2118916   17144  2810  1091.318412    Micro      2810\n",
       "2118915   17144  2809  1102.066864    Micro      2809\n",
       "2118914   17144  2808  1113.808746    Micro      2808\n",
       "...         ...   ...          ...      ...       ...\n",
       "10037151  47812     8  8677.300000    Other         8\n",
       "10037024  47810     8  7311.100000    Other         8\n",
       "10043898  47861     8  4566.390000    Other         8\n",
       "10043897  47861     7  4860.620000    Other         7\n",
       "10042785  47853     7  4913.680000    Other         7\n",
       "\n",
       "[2592000 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data#.sort_values(['id', 'time'])['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7e6528c6a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ind = np.random.choice(128)\n",
    "print(ind)\n",
    "plt.plot(output[ind,:,1].detach().cpu().numpy(), label='pred')\n",
    "# plt.plot(output[ind,:,1].detach().cpu().numpy(), label='pred_5')\n",
    "# plt.plot(output[ind,:,2].detach().cpu().numpy(), label='pred_9')\n",
    "\n",
    "plt.plot(batch['outputs'][ind,:,0], label='true')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
