{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader,Dataset, Subset\n",
    "import numpy as np\n",
    "import tft_model\n",
    "from data_formatters import ts_dataset  \n",
    "import data_formatters.base\n",
    "import expt_settings.configs\n",
    "import importlib\n",
    "from data_formatters import utils\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_formatters.utils' from '/home/arda/Desktop/thesis/submodules/Temporal_Fusion_Transform/data_formatters/utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExperimentConfig = expt_settings.configs.ExperimentConfig\n",
    "\n",
    "config = ExperimentConfig('m4', 'outputs')\n",
    "\n",
    "with open('data_formatter_m4.pkl', 'rb') as input:\n",
    "    data_formatter = pickle.load(input)\n",
    "\n",
    "# Sets up default params\n",
    "fixed_params = data_formatter.get_experiment_params()\n",
    "params = data_formatter.get_default_model_params()\n",
    "\n",
    "fixed_params.update(params)\n",
    "fixed_params['batch_first'] = True\n",
    "fixed_params['name'] = 'test'\n",
    "fixed_params['device'] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "fixed_params['minibatch_size'] = 256\n",
    "# fixed_params['category_count'] = [6]\n",
    "fixed_params['quantiles'] = [0.5]\n",
    "\n",
    "device = fixed_params['device']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arda/anaconda3/envs/thesis/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/m4_test.csv', index_col=0)\n",
    "test_transformed_data = data_formatter.transform_inputs(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_time_steps': 54, 'num_encoder_steps': 36, 'num_epochs': 100, 'early_stopping_patience': 5, 'multiprocessing_workers': 5, 'column_definition': [('id', <DataTypes.CATEGORICAL: 1>, <InputTypes.ID: 4>), ('time', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('value', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('time_cat', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('category', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>)], 'input_size': 3, 'output_size': 1, 'category_counts': [6], 'input_obs_loc': [0], 'static_input_loc': [2], 'known_regular_inputs': [1], 'known_categorical_inputs': [0], 'dropout_rate': 0.1, 'hidden_layer_size': 160, 'learning_rate': 0.001, 'minibatch_size': 256, 'max_gradient_norm': 0.01, 'num_heads': 4, 'stack_size': 1, 'batch_first': True, 'name': 'test', 'device': device(type='cuda'), 'quantiles': [0.5]}\n",
      "num_categorical_variables\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TFT(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(6, 160)\n",
       "  )\n",
       "  (static_input_layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "  (time_varying_embedding_layer): LinearLayer(\n",
       "    (layer): TimeDistributed(\n",
       "      (module): Linear(in_features=1, out_features=160, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (static_combine_and_mask): StaticCombineAndMask(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (linear_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=1, bias=True)\n",
       "      )\n",
       "      (hidden_linear_layer1): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (hidden_context_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (hidden_linear_layer2): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (elu1): ELU(alpha=1.0)\n",
       "      (glu): GLU(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "        (gated_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (add_and_norm): AddAndNorm(\n",
       "        (normalize): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (static_context_variable_selection_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_enrichment_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_state_h_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (static_context_state_c_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (historical_lstm_combine_and_mask): LSTMCombineAndMask(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (linear_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=320, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer1): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=320, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_context_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer2): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (elu1): ELU(alpha=1.0)\n",
       "      (glu): GLU(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (gated_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (add_and_norm): AddAndNorm(\n",
       "        (normalize): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (1): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=2)\n",
       "  )\n",
       "  (future_lstm_combine_and_mask): LSTMCombineAndMask(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (linear_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer1): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_context_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (hidden_linear_layer2): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (elu1): ELU(alpha=1.0)\n",
       "      (glu): GLU(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (gated_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (add_and_norm): AddAndNorm(\n",
       "        (normalize): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleList(\n",
       "      (0): GatedResidualNetwork(\n",
       "        (linear_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer1): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_context_layer): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (hidden_linear_layer2): LinearLayer(\n",
       "          (layer): TimeDistributed(\n",
       "            (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (elu1): ELU(alpha=1.0)\n",
       "        (glu): GLU(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (gated_layer): LinearLayer(\n",
       "            (layer): TimeDistributed(\n",
       "              (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (add_and_norm): AddAndNorm(\n",
       "          (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=2)\n",
       "  )\n",
       "  (lstm_encoder): LSTM(160, 160, batch_first=True)\n",
       "  (lstm_decoder): LSTM(160, 160, batch_first=True)\n",
       "  (lstm_glu): GLU(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gated_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (lstm_glu_add_and_norm): AddAndNorm(\n",
       "    (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (static_enrichment_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (self_attn_layer): InterpretableMultiHeadAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (qs_layers): ModuleList(\n",
       "      (0): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (1): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (2): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (3): Linear(in_features=160, out_features=40, bias=False)\n",
       "    )\n",
       "    (ks_layers): ModuleList(\n",
       "      (0): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (1): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (2): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (3): Linear(in_features=160, out_features=40, bias=False)\n",
       "    )\n",
       "    (vs_layers): ModuleList(\n",
       "      (0): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (1): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (2): Linear(in_features=160, out_features=40, bias=False)\n",
       "      (3): Linear(in_features=160, out_features=40, bias=False)\n",
       "    )\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (activation): Softmax(dim=-1)\n",
       "    )\n",
       "    (w_o): Linear(in_features=40, out_features=160, bias=False)\n",
       "  )\n",
       "  (self_attention_glu): GLU(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gated_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (self_attention_glu_add_and_norm): AddAndNorm(\n",
       "    (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder_grn): GatedResidualNetwork(\n",
       "    (linear_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer1): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_context_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (hidden_linear_layer2): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (elu1): ELU(alpha=1.0)\n",
       "    (glu): GLU(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (activation_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (gated_layer): LinearLayer(\n",
       "        (layer): TimeDistributed(\n",
       "          (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "    (add_and_norm): AddAndNorm(\n",
       "      (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (final_glu): GLU(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (activation_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (gated_layer): LinearLayer(\n",
       "      (layer): TimeDistributed(\n",
       "        (module): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (final_glu_add_and_norm): AddAndNorm(\n",
       "    (normalize): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_layer): LinearLayer(\n",
       "    (layer): TimeDistributed(\n",
       "      (module): Linear(in_features=160, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(tft_model)\n",
    "model = tft_model.TFT(fixed_params).to(device)\n",
    "model.load_state_dict(torch.load('m4_best_model_pinball_loss.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting valid sampling locations.\n",
      "# available segments=48000\n",
      "Max samples=48000 exceeds # available segments=48000\n",
      "1000 of 48000 samples done...\n",
      "2000 of 48000 samples done...\n",
      "3000 of 48000 samples done...\n",
      "4000 of 48000 samples done...\n",
      "5000 of 48000 samples done...\n",
      "6000 of 48000 samples done...\n",
      "7000 of 48000 samples done...\n",
      "8000 of 48000 samples done...\n",
      "9000 of 48000 samples done...\n",
      "10000 of 48000 samples done...\n",
      "11000 of 48000 samples done...\n",
      "12000 of 48000 samples done...\n",
      "13000 of 48000 samples done...\n",
      "14000 of 48000 samples done...\n",
      "15000 of 48000 samples done...\n",
      "16000 of 48000 samples done...\n",
      "17000 of 48000 samples done...\n",
      "18000 of 48000 samples done...\n",
      "19000 of 48000 samples done...\n",
      "20000 of 48000 samples done...\n",
      "21000 of 48000 samples done...\n",
      "22000 of 48000 samples done...\n",
      "23000 of 48000 samples done...\n",
      "24000 of 48000 samples done...\n",
      "25000 of 48000 samples done...\n",
      "26000 of 48000 samples done...\n",
      "27000 of 48000 samples done...\n",
      "28000 of 48000 samples done...\n",
      "29000 of 48000 samples done...\n",
      "30000 of 48000 samples done...\n",
      "31000 of 48000 samples done...\n",
      "32000 of 48000 samples done...\n",
      "33000 of 48000 samples done...\n",
      "34000 of 48000 samples done...\n",
      "35000 of 48000 samples done...\n",
      "36000 of 48000 samples done...\n",
      "37000 of 48000 samples done...\n",
      "38000 of 48000 samples done...\n",
      "39000 of 48000 samples done...\n",
      "40000 of 48000 samples done...\n",
      "41000 of 48000 samples done...\n",
      "42000 of 48000 samples done...\n",
      "43000 of 48000 samples done...\n",
      "44000 of 48000 samples done...\n",
      "45000 of 48000 samples done...\n",
      "46000 of 48000 samples done...\n",
      "47000 of 48000 samples done...\n",
      "48000 of 48000 samples done...\n"
     ]
    }
   ],
   "source": [
    "test_ds = ts_dataset.TSDataset(fixed_params, 48000, test_transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "            test_ds,\n",
    "            batch_size=fixed_params['minibatch_size'],\n",
    "            num_workers=2,\n",
    "            shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_forecasts = []\n",
    "truth = []\n",
    "dfs = []\n",
    "for idx, batch in enumerate(test_loader):\n",
    "    with torch.no_grad():\n",
    "        output, all_inputs, attention_components = model(batch['inputs'])\n",
    "        flat_prediction = pd.DataFrame(\n",
    "          output.detach().cpu().numpy()[:, :, 0],\n",
    "          columns=[\n",
    "              't+{}'.format(i)\n",
    "              for i in range(18)\n",
    "          ])\n",
    "        cols = list(flat_prediction.columns)\n",
    "#         flat_prediction['forecast_time'] = batch['time'][:, 54 - 1, 0]\n",
    "        flat_prediction['identifier'] = batch['identifier'][0][0].detach().cpu().numpy()\n",
    "        dfs.append(flat_prediction)\n",
    "#         df = pd.DataFrame({\n",
    "#             'id': batch['identifier'][0][0].detach().cpu().numpy(),\n",
    "#             'time': batch['time'][0][0].detach().cpu().numpy(),\n",
    "# #             'output': output[:,:,1].detach().cpu().numpy(),\n",
    "#             'category': batch['inputs'][:,:18,2].detach().cpu().numpy(),\n",
    "#             'time_cat': batch['inputs'][:,:18,1].detach().cpu().numpy(),\n",
    "            \n",
    "#         })\n",
    "#         print(batch['time'])\n",
    "#         print(batch['identifier'])\n",
    "#         dfs.append(df)\n",
    "#         a = output[:,:,1].detach().cpu().numpy()\n",
    "#         final_forecasts.append(a)\n",
    "#         truth.append(batch['outputs'])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions_unnormalized = data_formatter.format_predictions(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t+0</th>\n",
       "      <th>t+1</th>\n",
       "      <th>t+2</th>\n",
       "      <th>t+3</th>\n",
       "      <th>t+4</th>\n",
       "      <th>t+5</th>\n",
       "      <th>t+6</th>\n",
       "      <th>t+7</th>\n",
       "      <th>t+8</th>\n",
       "      <th>t+9</th>\n",
       "      <th>t+10</th>\n",
       "      <th>t+11</th>\n",
       "      <th>t+12</th>\n",
       "      <th>t+13</th>\n",
       "      <th>t+14</th>\n",
       "      <th>t+15</th>\n",
       "      <th>t+16</th>\n",
       "      <th>t+17</th>\n",
       "      <th>identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8378.749023</td>\n",
       "      <td>7881.981934</td>\n",
       "      <td>6580.670898</td>\n",
       "      <td>6233.371582</td>\n",
       "      <td>6154.186523</td>\n",
       "      <td>6192.274902</td>\n",
       "      <td>6257.579102</td>\n",
       "      <td>6394.767090</td>\n",
       "      <td>6224.277344</td>\n",
       "      <td>5892.783691</td>\n",
       "      <td>6307.762207</td>\n",
       "      <td>7863.509277</td>\n",
       "      <td>8517.051758</td>\n",
       "      <td>7783.321289</td>\n",
       "      <td>6822.369141</td>\n",
       "      <td>6491.555176</td>\n",
       "      <td>6474.672363</td>\n",
       "      <td>6351.558105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2480.031250</td>\n",
       "      <td>2267.679199</td>\n",
       "      <td>2020.953369</td>\n",
       "      <td>1864.181885</td>\n",
       "      <td>1759.690918</td>\n",
       "      <td>1731.235352</td>\n",
       "      <td>1766.891479</td>\n",
       "      <td>1862.302612</td>\n",
       "      <td>1892.631104</td>\n",
       "      <td>1886.419922</td>\n",
       "      <td>1910.872314</td>\n",
       "      <td>2119.693115</td>\n",
       "      <td>2315.180176</td>\n",
       "      <td>2191.164795</td>\n",
       "      <td>2106.827881</td>\n",
       "      <td>2072.013916</td>\n",
       "      <td>2062.997559</td>\n",
       "      <td>2044.868774</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13198.506836</td>\n",
       "      <td>13319.320312</td>\n",
       "      <td>13401.575195</td>\n",
       "      <td>13486.433594</td>\n",
       "      <td>13445.405273</td>\n",
       "      <td>13427.956055</td>\n",
       "      <td>13409.242188</td>\n",
       "      <td>13389.308594</td>\n",
       "      <td>13372.047852</td>\n",
       "      <td>13356.124023</td>\n",
       "      <td>13341.852539</td>\n",
       "      <td>13333.582031</td>\n",
       "      <td>13336.330078</td>\n",
       "      <td>13355.900391</td>\n",
       "      <td>13394.896484</td>\n",
       "      <td>13454.092773</td>\n",
       "      <td>13533.251953</td>\n",
       "      <td>13630.223633</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6544.335938</td>\n",
       "      <td>6579.310547</td>\n",
       "      <td>6572.719238</td>\n",
       "      <td>6548.825684</td>\n",
       "      <td>6541.416992</td>\n",
       "      <td>6533.903809</td>\n",
       "      <td>6531.274902</td>\n",
       "      <td>6540.048828</td>\n",
       "      <td>6540.098145</td>\n",
       "      <td>6534.760742</td>\n",
       "      <td>6532.979004</td>\n",
       "      <td>6538.053223</td>\n",
       "      <td>6546.255859</td>\n",
       "      <td>6551.487793</td>\n",
       "      <td>6552.711426</td>\n",
       "      <td>6549.496094</td>\n",
       "      <td>6541.737305</td>\n",
       "      <td>6534.537109</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4355.229004</td>\n",
       "      <td>4369.060547</td>\n",
       "      <td>4371.007812</td>\n",
       "      <td>4367.020508</td>\n",
       "      <td>4397.458984</td>\n",
       "      <td>4405.282715</td>\n",
       "      <td>4407.695312</td>\n",
       "      <td>4399.464355</td>\n",
       "      <td>4397.342285</td>\n",
       "      <td>4395.135254</td>\n",
       "      <td>4381.610840</td>\n",
       "      <td>4371.892090</td>\n",
       "      <td>4370.213379</td>\n",
       "      <td>4369.753906</td>\n",
       "      <td>4369.895508</td>\n",
       "      <td>4373.467285</td>\n",
       "      <td>4380.957031</td>\n",
       "      <td>4387.615234</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>5245.925293</td>\n",
       "      <td>6445.167480</td>\n",
       "      <td>7530.265137</td>\n",
       "      <td>7742.284668</td>\n",
       "      <td>7550.016113</td>\n",
       "      <td>5513.492676</td>\n",
       "      <td>4774.483887</td>\n",
       "      <td>4849.315918</td>\n",
       "      <td>5147.564941</td>\n",
       "      <td>5419.241211</td>\n",
       "      <td>5281.185059</td>\n",
       "      <td>5274.545898</td>\n",
       "      <td>5754.937988</td>\n",
       "      <td>6706.014160</td>\n",
       "      <td>7609.563965</td>\n",
       "      <td>8051.938477</td>\n",
       "      <td>7886.371094</td>\n",
       "      <td>5433.889160</td>\n",
       "      <td>47996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>953.991150</td>\n",
       "      <td>1000.617065</td>\n",
       "      <td>1030.238647</td>\n",
       "      <td>1033.891235</td>\n",
       "      <td>1003.713501</td>\n",
       "      <td>951.120544</td>\n",
       "      <td>911.866760</td>\n",
       "      <td>908.368774</td>\n",
       "      <td>956.533264</td>\n",
       "      <td>999.645447</td>\n",
       "      <td>1010.194336</td>\n",
       "      <td>1010.434265</td>\n",
       "      <td>1008.076782</td>\n",
       "      <td>1012.298462</td>\n",
       "      <td>1016.385925</td>\n",
       "      <td>1017.854614</td>\n",
       "      <td>1018.234009</td>\n",
       "      <td>1018.404053</td>\n",
       "      <td>47997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>5081.349121</td>\n",
       "      <td>5119.013672</td>\n",
       "      <td>5129.634277</td>\n",
       "      <td>5137.151855</td>\n",
       "      <td>5157.852051</td>\n",
       "      <td>5179.356445</td>\n",
       "      <td>5189.158203</td>\n",
       "      <td>5183.845703</td>\n",
       "      <td>5180.527832</td>\n",
       "      <td>5183.286133</td>\n",
       "      <td>5188.284668</td>\n",
       "      <td>5192.915039</td>\n",
       "      <td>5189.431152</td>\n",
       "      <td>5168.453613</td>\n",
       "      <td>5131.624512</td>\n",
       "      <td>5098.592773</td>\n",
       "      <td>5087.344238</td>\n",
       "      <td>5107.137207</td>\n",
       "      <td>47998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>4508.474609</td>\n",
       "      <td>4539.379883</td>\n",
       "      <td>4548.559570</td>\n",
       "      <td>4563.728027</td>\n",
       "      <td>4588.697266</td>\n",
       "      <td>4623.194336</td>\n",
       "      <td>4662.862793</td>\n",
       "      <td>4710.568359</td>\n",
       "      <td>4760.759277</td>\n",
       "      <td>4809.450684</td>\n",
       "      <td>4847.111328</td>\n",
       "      <td>4875.658691</td>\n",
       "      <td>4896.024414</td>\n",
       "      <td>4913.117188</td>\n",
       "      <td>4928.718262</td>\n",
       "      <td>4937.504883</td>\n",
       "      <td>4939.519043</td>\n",
       "      <td>4940.780273</td>\n",
       "      <td>47999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5163.011230</td>\n",
       "      <td>5179.331055</td>\n",
       "      <td>5192.561035</td>\n",
       "      <td>5208.662109</td>\n",
       "      <td>5225.034668</td>\n",
       "      <td>5234.486816</td>\n",
       "      <td>5277.526367</td>\n",
       "      <td>5318.143066</td>\n",
       "      <td>5348.044434</td>\n",
       "      <td>5342.104980</td>\n",
       "      <td>5317.719727</td>\n",
       "      <td>5323.365234</td>\n",
       "      <td>5319.001465</td>\n",
       "      <td>5319.508301</td>\n",
       "      <td>5323.227539</td>\n",
       "      <td>5321.768555</td>\n",
       "      <td>5315.850586</td>\n",
       "      <td>5325.297852</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48000 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              t+0           t+1           t+2           t+3           t+4  \\\n",
       "0     8378.749023   7881.981934   6580.670898   6233.371582   6154.186523   \n",
       "1     2480.031250   2267.679199   2020.953369   1864.181885   1759.690918   \n",
       "2    13198.506836  13319.320312  13401.575195  13486.433594  13445.405273   \n",
       "3     6544.335938   6579.310547   6572.719238   6548.825684   6541.416992   \n",
       "4     4355.229004   4369.060547   4371.007812   4367.020508   4397.458984   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "123   5245.925293   6445.167480   7530.265137   7742.284668   7550.016113   \n",
       "124    953.991150   1000.617065   1030.238647   1033.891235   1003.713501   \n",
       "125   5081.349121   5119.013672   5129.634277   5137.151855   5157.852051   \n",
       "126   4508.474609   4539.379883   4548.559570   4563.728027   4588.697266   \n",
       "127   5163.011230   5179.331055   5192.561035   5208.662109   5225.034668   \n",
       "\n",
       "              t+5           t+6           t+7           t+8           t+9  \\\n",
       "0     6192.274902   6257.579102   6394.767090   6224.277344   5892.783691   \n",
       "1     1731.235352   1766.891479   1862.302612   1892.631104   1886.419922   \n",
       "2    13427.956055  13409.242188  13389.308594  13372.047852  13356.124023   \n",
       "3     6533.903809   6531.274902   6540.048828   6540.098145   6534.760742   \n",
       "4     4405.282715   4407.695312   4399.464355   4397.342285   4395.135254   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "123   5513.492676   4774.483887   4849.315918   5147.564941   5419.241211   \n",
       "124    951.120544    911.866760    908.368774    956.533264    999.645447   \n",
       "125   5179.356445   5189.158203   5183.845703   5180.527832   5183.286133   \n",
       "126   4623.194336   4662.862793   4710.568359   4760.759277   4809.450684   \n",
       "127   5234.486816   5277.526367   5318.143066   5348.044434   5342.104980   \n",
       "\n",
       "             t+10          t+11          t+12          t+13          t+14  \\\n",
       "0     6307.762207   7863.509277   8517.051758   7783.321289   6822.369141   \n",
       "1     1910.872314   2119.693115   2315.180176   2191.164795   2106.827881   \n",
       "2    13341.852539  13333.582031  13336.330078  13355.900391  13394.896484   \n",
       "3     6532.979004   6538.053223   6546.255859   6551.487793   6552.711426   \n",
       "4     4381.610840   4371.892090   4370.213379   4369.753906   4369.895508   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "123   5281.185059   5274.545898   5754.937988   6706.014160   7609.563965   \n",
       "124   1010.194336   1010.434265   1008.076782   1012.298462   1016.385925   \n",
       "125   5188.284668   5192.915039   5189.431152   5168.453613   5131.624512   \n",
       "126   4847.111328   4875.658691   4896.024414   4913.117188   4928.718262   \n",
       "127   5317.719727   5323.365234   5319.001465   5319.508301   5323.227539   \n",
       "\n",
       "             t+15          t+16          t+17  identifier  \n",
       "0     6491.555176   6474.672363   6351.558105           1  \n",
       "1     2072.013916   2062.997559   2044.868774           2  \n",
       "2    13454.092773  13533.251953  13630.223633           3  \n",
       "3     6549.496094   6541.737305   6534.537109           4  \n",
       "4     4373.467285   4380.957031   4387.615234           5  \n",
       "..            ...           ...           ...         ...  \n",
       "123   8051.938477   7886.371094   5433.889160       47996  \n",
       "124   1017.854614   1018.234009   1018.404053       47997  \n",
       "125   5098.592773   5087.344238   5107.137207       47998  \n",
       "126   4937.504883   4939.519043   4940.780273       47999  \n",
       "127   5321.768555   5315.850586   5325.297852       48000  \n",
       "\n",
       "[48000 rows x 19 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions_unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(forecast, actual):\n",
    "    # Symmetric Mean Absolute Percentage Error (SMAPE)\n",
    "    return np.mean(2 * np.abs(forecast - actual) / (np.abs(actual) + np.abs(forecast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = pd.read_csv('/home/arda/Desktop/thesis/datasets/m4/Test/Monthly-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(actuals.drop(columns=['V1']).values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(864000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(all_predictions_unnormalized.drop(columns=['identifier']).values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15969078213737106"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symmetric_mean_absolute_percentage_error(np.concatenate(all_predictions_unnormalized.drop(columns=['identifier']).values) ,np.concatenate(actuals.drop(columns=['V1']).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "      <th>category</th>\n",
       "      <th>time_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2118918</th>\n",
       "      <td>17144</td>\n",
       "      <td>2812</td>\n",
       "      <td>1085.036158</td>\n",
       "      <td>Micro</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118917</th>\n",
       "      <td>17144</td>\n",
       "      <td>2811</td>\n",
       "      <td>1088.157304</td>\n",
       "      <td>Micro</td>\n",
       "      <td>2811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118916</th>\n",
       "      <td>17144</td>\n",
       "      <td>2810</td>\n",
       "      <td>1091.318412</td>\n",
       "      <td>Micro</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118915</th>\n",
       "      <td>17144</td>\n",
       "      <td>2809</td>\n",
       "      <td>1102.066864</td>\n",
       "      <td>Micro</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118914</th>\n",
       "      <td>17144</td>\n",
       "      <td>2808</td>\n",
       "      <td>1113.808746</td>\n",
       "      <td>Micro</td>\n",
       "      <td>2808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037151</th>\n",
       "      <td>47812</td>\n",
       "      <td>8</td>\n",
       "      <td>8677.300000</td>\n",
       "      <td>Other</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10037024</th>\n",
       "      <td>47810</td>\n",
       "      <td>8</td>\n",
       "      <td>7311.100000</td>\n",
       "      <td>Other</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10043898</th>\n",
       "      <td>47861</td>\n",
       "      <td>8</td>\n",
       "      <td>4566.390000</td>\n",
       "      <td>Other</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10043897</th>\n",
       "      <td>47861</td>\n",
       "      <td>7</td>\n",
       "      <td>4860.620000</td>\n",
       "      <td>Other</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10042785</th>\n",
       "      <td>47853</td>\n",
       "      <td>7</td>\n",
       "      <td>4913.680000</td>\n",
       "      <td>Other</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2592000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  time        value category  time_cat\n",
       "2118918   17144  2812  1085.036158    Micro      2812\n",
       "2118917   17144  2811  1088.157304    Micro      2811\n",
       "2118916   17144  2810  1091.318412    Micro      2810\n",
       "2118915   17144  2809  1102.066864    Micro      2809\n",
       "2118914   17144  2808  1113.808746    Micro      2808\n",
       "...         ...   ...          ...      ...       ...\n",
       "10037151  47812     8  8677.300000    Other         8\n",
       "10037024  47810     8  7311.100000    Other         8\n",
       "10043898  47861     8  4566.390000    Other         8\n",
       "10043897  47861     7  4860.620000    Other         7\n",
       "10042785  47853     7  4913.680000    Other         7\n",
       "\n",
       "[2592000 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data#.sort_values(['id', 'time'])['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7e6528c6a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deVzU1f748ddhExAUEcUFEDT3XXHFUsuMytIWy2yzutfbdttu62293X639fZt9Zql2WJmVraYa6VpLiUqKu6CqLiBgIDKPuf3xxkNjWWAYT7D8H4+Hjxm+Hw+85k34/ieM+dzzvsorTVCCCEaFi+rAxBCCOF6kvyFEKIBkuQvhBANkCR/IYRogCT5CyFEA+RjdQDlCQsL09HR0VaHIYQQ9cb69euPaa1bOHq8Wyb/6OhoEhISrA5DCCHqDaXUvuocL90+QgjRAEnyF0KIBkiSvxBCNEBu2edfnuLiYtLS0igoKLA6lDrj7+9PREQEvr6+VocihPBw9Sb5p6WlERwcTHR0NEopq8NxOq01mZmZpKWlERMTY3U4QggPV2+6fQoKCmjevLlHJn4ApRTNmzf36G82Qgj3UW+SP+Cxif80T//7hBDuo950+wghhFs6tBFSf4UWXaBVTwgKh3rQkKsy+SulZgBjgHStdY9y9j8C3FjmfF2BFlrrLKVUKpAHlAIlWutYZwVe3wUFBXHixAmrwxBC1FROGvz0PGyec/b2wDDzIdCqJ7TqZW6bnwfe7tXWdiSamcA7wMfl7dRavwq8CqCUugJ4UGudVeaQkVrrY7WMs14oLS3F29vb6jCEEHWp8ASsegNWvw1aw7CHYMBf4Pg+OLIFjmw2t79NhdIi8xgff2jZ7ewPhfBu0CjYsj+jyuSvtV6hlIp28Hw3ALNrE5C7Sk1NJT4+nkGDBrFx40Y6derExx9/TLdu3bj99ttZsmQJ9957LwMGDOCee+4hIyODwMBA3n//fbp06cLevXuZOHEiJSUlxMfHW/3nCCGqy1YKibPg5xfgxFHocS2MehZCosz+pm2h3dA/ji8thmO77B8I9p/t38GGj+wHKAiN+fO3hODWLuk2ctr3EKVUIBAP3FtmswaWKKU08J7Welolj58MTAaIioqq9Ln+9f1Wth3KrXXMZXVr04Rnr+he6TE7d+5k+vTpxMXFcfvttzNlyhTAjM//9ddfAbjooouYOnUqHTt25LfffuPuu+/m559/5v777+euu+7illtu4d1333Vq7EKIOpa8DJY8BUeTIHIQTPgMIqroxfb2hfDu5qf3BLNNa8g9VOYDYTMc3gzbvjX7/ZvCY9Uq0VNjzuyEugJYdU6XT5zW+pBSqiWwVCm1Q2u9orwH2z8YpgHExsa65cLCkZGRxMXFAXDTTTfx1ltvAXD99dcDcOLECVavXs348ePPPKawsBCAVatW8dVXXwFw880389hjj7kydCFETWTshCVPw+7FENIOxs+EbuNq3jJXynxDaNoWOpfpASjIhfRt5huFiy4WOzP5T+CcLh+t9SH7bbpSah4wECg3+VdHVS30unLuUMzTvzdu3BgAm81GSEgIiYmJDj1eCOGmTh6D5S9Cwofg1xgu/jcM+hv4NKqb5/NvAlGD6+bcFXDKOH+lVFNgOPBtmW2NlVLBp+8Do4EkZzyfVfbv38+aNWsAmD17NsOGDTtrf5MmTYiJiWHu3LmAmbW7adMmAOLi4vj8888BmDVrlgujFkI4rLgAVr0Jb/U1iT/2drhvI8TdV3eJ3yJVJn+l1GxgDdBZKZWmlLpDKXWnUurOModdBSzRWp8ssy0c+FUptQn4HfhBa73ImcG7WteuXfnoo4/o1asXWVlZ3HXXXX86ZtasWUyfPp3evXvTvXt3vv3WfB6++eabvPvuuwwYMICcnBxXhy6EqIzWkPQ1vDsAlj5jLtzevQYufw0ah1kdXZ1QWrtf93psbKw+dzGX7du307VrV4siMqN9xowZQ1JS3X55sfrvFKLBObAOFv8T0n6H8J5wyQvQfoTVUVWbUmp9deZSudesAyGEqGtaw/H9ZuRO0lfmJygcrnwH+kwEr4YxV0eSv4Oio6PrvNUvhHCykiLI2HH2WPujW6DA3vXqEwDDH4Oh90GjIGtjdTFJ/kIIz3Aqy7Tmyyb6jJ1gKzb7fQPNmPse1/wxqaplN/ALtDZui0jyF0LUP8f3w6FEe0venvBzDvyxP6iVSfAdR/+R6ENjGkyXjiMk+Qsh6o/iAlj8BCTMML8rL2je0cy6HfCXP0olBLW0Ns56QJK/EKJ+OLYH5k4yffaD7za1dVp2bbDdNrVVrxZzsdLx48fP1PIRQrjYli9h2nDITYOJX0D8ixDRXxJ/LUjyd1BFyb+0tNSCaIRoIIrz4fv74as7zMXaO3+FTpdYHZVHkG4fBz3++OMkJyfTp08ffH19CQoKonXr1iQmJrJgwYKzJoC99tprnDhxgueee47k5ORySzwLIapwbLe9mycJ4u6HC582lTKFU9TP5L/wcXN135la9YRLX6pw90svvURSUhKJiYksX76cyy+/nKSkJGJiYkhNTa3wcZMnTy63xLMQohKb58L8B8DbDybOhU6jrY7I49TP5O8GBg4cSExMTKXHVFbiWQhRjuJ8WPiYWfAkcjBcOx2aRlgdlUeqn8m/kha6q5wu4wzg4+ODzWY783tBQQFQdYlnIUQZZbt5hj0II5+Ubp46JBd8HRQcHExeXl65+8LDw0lPTyczM5PCwkLmz58PVF7iWQhRxuYv4L3hZpWrG7+EUc9J4q9j9bPlb4HmzZsTFxdHjx49CAgIIDw8/Mw+X19fnnnmGQYNGkRMTMxZF3RnzZrFXXfdxQsvvEBxcTETJkygd+/eVvwJQrif4nxY+Chs+BiihsA1080qV6LOSUlnN9NQ/k4hyNhlunnSt8Kwh+zdPNIerSkp6SyEcH+b5sD8B8HXH278CjqOsjqiBkeSvxDCdYpOmW6ejZ9A1FAzmqdJG6ujapDqVfLXWnv0Iuju2AUnhNOcyoKZl0P6djj/YRjxhHTzWKjevPL+/v5kZmbSvHlzj/wA0FqTmZmJv7+/1aEIUTd+fA6O7TKjeaSbx3L1JvlHRESQlpZGRkaG1aHUGX9/fyIiZEKL8EAH15sRPUPukcTvJqpM/kqpGcAYIF1r3aOc/Y8AN5Y5X1eghdY6SykVD7wJeAMfaK1rPDvL19e3yhm1Qgg3ZLPBgkdMjf3hj1kdjbBzZJLXTCC+op1a61e11n201n2AJ4Bf7InfG3gXuBToBtyglOrmhJiFEPVJ4izT8r/43+DfxOpohF2VyV9rvQLIcvB8NwCz7fcHAnu01ila6yLgc2BsjaIUQtRP+dmmrz9qCPS6zupoRBlOK++glArEfEP4yr6pLVBmUU3S7NsqevxkpVSCUirBk/v1hWhQlr0I+Vlw6SvggQM16jNn1va5AliltT79LaG8f+kKxzJqradprWO11rEtWrRwYlhCCEscSYJ170PsHdC6l9XRiHM4M/lP4I8uHzAt/cgyv0cAh5z4fEIId6W1ucgb0AxG/tPqaEQ5nJL8lVJNgeHAt2U2rwM6KqVilFJ+mA+H75zxfEIIN7flS9i/Gi56FgJDrY5GlMORoZ6zgRFAmFIqDXgW8AXQWk+1H3YVsERrffL047TWJUqpe4HFmKGeM7TWW50bvhDC7RTmwdKnoU0/6Huz1dGIClSZ/LXWNzhwzEzMkNBzty8AFtQkMCFEPbXiVcg7DNfPAi9ZMsRdyb+MEMJ5MnbBmimmxR/R3+poRCUk+QshnENrU7HTL9CsxCXcmiR/IYRz7JgPKctg5FPQOMzqaEQVJPkLIWqv6BQs+ieE94DY262ORjig3lT1FEK4sVVvQM5+uHqh1OivJ6TlL4Sonay98Osb0PM6aDfU6miEgyT5CyFqZ/E/wdsXLn7e6khENUjyF0LU3K4lsHOBqdPfpLXV0YhqkOQvhKiZkkJY9BiEdYJBd1odjagmuTIjhKiZNe9AVgrcPA98/KyORlSTtPyFENWXkwYrXoOuV0KHC62ORtSAJH8hRPUtecrM6L3k/1kdiaghSf5CiOpJ+QW2zoPz/wEhUVZHI2pIkr8QwnGlxaZ+T7NoGPp3q6MRtSAXfIUQjvt9GmTsgBvmgK+/1dGIWpCWvxDCMXlHzYLsHS+BzvFWRyNqSZK/EMIxPz4LpYUQ/6LVkQgnkOQvhKja/rWwaTYMvQ+ad7A6GuEE0ucvhLNoDZvngG+AGf+ulNUR1U5pCWTugSNbYOV/oUkEnP+Q1VEJJ5HkL4QzFOTAt/fC9u/M7xED4ZL/QOQAa+NyVGEeHN1qEv3pn/RtUFJg9vsEwHUfgV9ja+MUTlNl8ldKzQDGAOla6x4VHDMCeAPwBY5prYfbt6cCeUApUKK1jnVO2EK4kYMb4MvbzKzXi5+HgFD4+d8wfRT0uAYuehaatbM6SkNrs7j6kS1wZPMfiT4r5Y9jAppBq14w4C/Qqqf5CetkKncKj+FIy38m8A7wcXk7lVIhwBQgXmu9XynV8pxDRmqtj9UqSiHckdZm6OPiJyEoHG5bCJEDzb7uV8Hqt2DVW7B9Pgy+y3SZ+Dd1bYyZyZCW8EeiP5oEpzL/2N8sxiT33hP/SPRN2tT/LitRpSqTv9Z6hVIqupJDJgJfa633249Pd05oQrix/OPw3b2w/XvodCmMmwKBoX/sbxQEI/8J/W413wJWvQEbP7Fvm1S3q12dyoKkryBxFhzaaLZ5N4KWXaHzZaZV36onhHcH/yZ1F4dwa0prXfVBJvnPL6/bRyl1urunOxAMvKm1/ti+by+QDWjgPa31tEqeYzIwGSAqKqr/vn37qvu3COEaB9fD3Nsg9yCM+hcMuafqlvKhjbD4Kdj3K4R1htEvQMeLndfCLi2B5J9Mwt+5EEqLzHq6fSZC+5EQ1lG6bTycUmp9dbrWndH88AH6AxcBAcAapdRarfUuIE5rfcjeFbRUKbVDa72ivJPYPximAcTGxlb9iSSEq2kNv02FJU9DcCu4bZHjF3Tb9IVJ82HHD7D0afhsvEnKl/w/0wKvqaPbTMLf/AWcTIfA5hB7h0n6rXvV/LzC4zkj+adhLvKeBE4qpVYAvYFdWutDYLqClFLzgIFAuclfCLeWn21G8+yYb7pOxr57djePI5SCrmOg42hImA7LX4Kpw6DvzTDySQgOd+w8p7Jgy5cm6R9OBC8f6BRvEv55F0ttfeEQZyT/b4F3lFI+gB8wCPg/pVRjwEtrnWe/PxqQRT5F/ZO2Hr6cBLmHzPDNwXfXrrvGx89cAO51Pax41Vw0TvoKhj0AQ+418wTOVVoMe360d+ssAlux6buPfxl6XguNw2oej2iQHBnqORsYAYQppdKAZzF9/Gitp2qttyulFgGbARvwgdY6SSnVHpinzH8SH+AzrfWiuvkzhKgDWsPa/8HSZyC4Ndy+GCKcOFo5MNSUShjwF/McP78ACTPhomeg53jw8oIjSWZm7eY5cDIDAsNg4GToc4O5aCtEDTl0wdfVYmNjdUJCgtVhiIYsPxu+uQd2/gCdL4dx75rx73Up9VdY/E84vAla9wFtM0M0vXxNIbU+N8J5oxr8hdsjOQWs3J2BBny9FT5eXvh6K3y9vfDx9sLXS5nbM9vMMX6n73srfL288PXxwt/HPMYTWHHBVwjPkpZgRvPkHYb4l8zi5K4Y9x49DP66HLZ8Ya4H+DeBS1+BHtdC4+Z1//xurLCklB+3pfNFwgFW7s7A5qQ2a4CvN5Piornzgg40DWxYH6rS8hfiNK1hzbumemWTNjB+JrTtb3VUDVrSwRzmJhzg202HOH6qmNZN/bm2fwRjerUh0M+bEpumpNRGcammuNRGic3cL7H/bradvm8/1v6YklLNprTjzN98mCb+Ptw5ogOThkYT6Fc/28TS8heiJk5lwbf3wM4F0GWMGc0TEGJ1VA1S1skivtl4kLnr09h+OBc/Hy8u6d6K8f0jiDsvDG8v534Lu3tELq8t2ckri3by4apU/n7heUwYEIWfj2d0B1VEWv5CHD8AH4+F4/vN5KtBf5PyBi5WUmpjxe4M5iak8eP2oxSXanpFNGV8/wiu7N3WJV0yCalZvLJoJ7+nZhEZGsCDozoxtk9bp3/Y1JXqtvwl+YuGLWMXfDIOik7AxC8garDVETUoyRknmJuQxtcb0kjPK6R5Yz/G9W3L+NgIurRyfekJrTXLd2Xw6qKdbDucS+fwYP4xuhMXdwtHuXmDQLp9hHDUoUT49GpQXjDpBxk66SJ5BcXM33yYuQkH2LD/ON5eipGdWzI+NoKRnVta2t2ilIlleMcW/LDlMK8v3cXkT9bTNyqERy/pwpAOnnPhXVr+omHatxo+u95U2bzlW1mdygWSM04wZVkyP2w5REGxjY4tgxgfG8G4vm1pGeyei8EXl9r4cn0ab/64myO5BZzfMYxHL+lCzwgXV2d1gHT7CFGV3Uthzs3QNAJu+cbcijqTnlvAGz/tZs66A/j7eDG2b1vG94+gT2SI23elnFZQXMona/YxZfkesk8Vc1nPVjx0cWfOaxlkdWhnSPIXojJJX8PXfzXF1G76Wsoi1KG8gmLeX5HC+yv3Ulxq48ZBUfz9oo6EBTWyOrQayyso5v2Ve5m+MoX84lKu7R/B/aM60TaknJIcLibJX9StwjzYu8IUN6snrbYz1s+E7x+AqCEw8XPXL6zSQBSV2Pjst328/fMeMk8WMaZXax4e3ZnoMM9ZAjLzRCHvLkvm07Wm9PykuGgeHt3Z6usVkvxFHfr5/8GKV0wlyiveBC9vqyNyzKo3Tf2c8y6G6z4Gv0CrI/I4Npvmhy2HeW3JTvZlnmJI++Y8fmkXekd67nyJg8fzeWPpLuauT2NAdDP+d1N/y77ZyGgfUbf2/gJ+QWZVqsJcuPp98HHjr/Fam5W0Vv4Xul8NV70nJY/rwOo9x3hx4Q62HMyhS6tgPrxtACM6tag3ffo11TYkgFfH9+b8Ti14ZO4mxr6zivdviaVbG/dfIU2Sv3Bc4QmzitXQv5vqkkueNN1A138Kfm74ld5mg4WPwLoPoP8kuPz1+vNNpZ7YdiiXlxft4JddGbQNCeC/43szrm/9mRjlLFf2bkN080Amf7yea6eu5vXr+hDfo5XVYVXKs+cvC+c6sBZsJRB9Pgy9F658B1KWwydXmTVt3UlpMcz7m0n8cffDmDck8TtRWvYpHpqTyOVvryTxwHGevKwrP/1jONf0j2hwif+0XhEhfHdvHB3Dg7nz0/W8/dNu3LFb/TRp+QvH7V1pygufngXb72ZoFAxf/QU+GmNGzwS1tDZGgOICmDsJdi2Ei56F8x+yOiKPkX2yiCnL9/DR6n2gYPIF7bl7+HkNriJmRVo28WfO5ME88fUW/rt0FzuP5vHqtb0J8HO/hockf+G4vStMlcuyXTzdx0GjIPj8JpgRbyZMhURaF2NhHsy+wdTGv/y/ZqEUUWsFxaV8uCqVKcv3cKKwhGv7RfDgxZ1o4wZDHN2Nv683r1/Xm86tgnl50Q72ZZ5i2i39ad3UvV4r6fYRjinIMevFxlzw533njTKTpU4eMx8Ax3a7Pj6Ak5nw0RVm9u7V0yTxO8GOI7m8tHAHF7yyjJcX7WBAdCiL7r+AV8f3lsRfCaUUdw7vwAe3xJKScYIr31nFxv3ZVod1Fkn+wjH71piVpWLOL39/1GCYNB9KC80HwOFNro0v9xDMvAyOboMJs6DXda59fg9yOCef935JJv6NFcS/sZL3V6bQvU0TPp88mBmTBtC5VbDVIdYbF3UNZ949cQT4enP9tLXM25hmdUhnSLePcEzqSvBuBBEDKz6mdS+4bZEpjzxzjKmS2W5I3ceWlQIfj4NTmXDTVxV/QIkK5RYUs2jLEeZtPMjavZloDX2jQnh+bHcu79ma5vV4Vq7VOoUH8+09cdw1az0PztnEjiN5PHpJF8svjMskr7qiNez50YyM8XXPolXVMvV8MyN20vyqjz1+wJRJzjlohoF2HFU3MWltuni+vA1Ki0zil5W3HFZUYmP5znS+STzIj9vTKSqxERPWmLF92jCuT1uPmpHrDopLbfzr+618unY/F3ZpyZsT+hDs77wL5U6f5KWUmgGMAdK11j0qOGYE8AbgCxzTWg+3b48H3gS8gQ+01i85Gli9d3ADzLoWBt8N8S9aHU3tnMqCI1tgxBOOHR8Sab4BfHoVzJ4A17wP3a9yXjw5B2Hz55D4GWTugeDWcNtCaNnVec/hoWw2zfr92czbeJAFWw5z/FQxzRv7MXFgFOP6tqV3RFOPn5hlFV9vL14Y15POrZrw3HdbuXrKaj64NZZ2za35kHWk22cm8A7wcXk7lVIhwBQgXmu9XynV0r7dG3gXuBhIA9Yppb7TWm9zRuBuL/lnc/vbe6YUQng3a+OpjX2rAV297pSgFnDrfJP8v7wdCnKh/601j6E4H3b8AImzIHmZiSdqKMQ9YB9xJP3QldmTnse8jQf5NvEQadn5BPh6M7p7OOP6tmXYeWH4esvlP1e5eXA7OrRozN2zNjD23VVMubEfQzu4vsBglclfa71CKRVdySETga+11vvtx6fbtw8E9mitUwCUUp8DY4GGkfxTlkHz80w/9MJH4dbv618htNP2rgCfgOp3qQSEmLH/X9wM399nykEM/bvjj9caDvxuEv7WeebxTaNg+KPQewKEtq9ePA1MWvYpFm45wrebDpJ0MBcvBcM6tuAfozsxulsrGjeSS35WGdohjG/vieOOjxK4ZfrvPHtld24e3M6lMTjjX78T4KuUWg4EA29qrT8G2gIHyhyXBgyq6CRKqcnAZICoqCgnhGWhwhMmaQ2+C0JjYP6DsPVr6HGN1ZHVTOpKM5qnJjV8/AJhwmxTRnnJU2Ym8IVPVf5BmJMGm+zdOlnJ4BsI3cZCn4nQbhh4SSu1InuPnWRh0mEWJR1hc1oOAL0imvLMmG6M6d3abRdNaYjaNW/MvLuHcv/niTz9TRI7j+Ty7BXdXfYtzBnJ3wfoD1wEBABrlFJrgfL+d1d4dVlrPQ2YBuaCrxPiss6+1WArhg4jIWa4KSW8+CnoeImZEFWfnDwG6dug57U1P4ePH1w7A+Y3gZWvmTkDl75ydhIvOgU75ptWfsovgIZ2cWZ2brex0q1TAa01u9NPsHDLERYmHWbHkTwAekeG8PilXbi0RyvL+pRF1YL9fXn/llheWbyD935JITn9JNMnxRLoV/ffypzxDGmYi7wngZNKqRVAb/v2slM9I4BDTng+95ey3AyLjBpi6slc+irMGG0S36jnLA6umlJXmtvociZ3VYeXN1zxlhkxtPpt04Uz9l1TKC5xFiTNg6I8CImC4Y/Zu3Viah+/B9Jas/VQLouSjrAg6TApGSdRCmLbNeOZMd2I79FKJmDVI95eiicu7Urn8GBWJ2cS4OuaUhDOSP7fAu8opXwAP0zXzv8BO4COSqkY4CAwAXN9wPOlLDfdJL72/4BRg6D3RFj9DvS5CcLOszS8atm70pRwbtOn9udSCi7+N/iHmDLLOxdBYY69W2ecvVsnTrp1ymGzaRLTjrMoybTwD2Tl4+2lGBQTym1xMVzSLZyWTaRLpz67ul8EV/dz3ZKijgz1nA2MAMKUUmnAs5ghnWitp2qttyulFgGbARtmSGeS/bH3AosxQz1naK231slf4U7yjkL6VlNQrKxRz5lujYWPmvHo9eXib+pK8w3G20njkZWCCx42yydu/97U2O92pXTrlKPUpklIzWJh0hEWbz3C4ZwCfL0VceeFce/I87i4WytCG8vaBKJmHBntc4MDx7wKvFrO9gXAgpqFVk/t/cXcdhh59vbgcDNOfvETsHMBdLnc9bFVV94ROLYL+t7k/HP3n2R+xFm01iQdzGXu+gMs2HKEYycK8fPxYninFjxySWcu6hpO0wCpoClqT8Z6OVvyMghoBq16/XnfwL/Cho9h0ePQ4cI/uoXc1d7T/f1SLqGuZZ0s4puNB/ki4QA7juTRyMeLUV3Die/RipFdWhIkwzKFk8k7ypm0Nv39MReUv3CIty9c9oqpPLnqTRjxuMtDrJbUFdCoKbTubXUkHqnUplm5O4MvEg6wdNtRiks1vSOa8sK4HlzRu4208EWdkuTvTMd2Q94haD+y4mNiLjD93L/+nxnR0izaZeFV296VEB0nK2A52b7Mk8xNSOPL9WkcyS0gtLEftwyJZnxsBF1auf/ar8IzSPJ3ppRl5rb9iMqPG/0C7FoEi5805YfdUU4aZO+FgZOtjsQj5BeVsjDpMF8kHGBtShZeCoZ3asGzV3Tjoq7h+PnICCfhWpL8nSlluWnJVzU+vWlbuOAR+OlfsPvHuqt6WRun+/ulPHKNaa3ZlJbDnHUHmL/pEHmFJbRrHsgjl3Tmmn4RtGoqQzOFdST5O0tpsUmYPR0s4TDkHtj4qRn6GbOmZqUT6lLqSggIhZbdrY6k3jl2ovDMxdtdR08Q4OvNZT1bc11sBANjQqVqpnALkvyd5eAGM0O1/QjHjvdpZEoczLoG1k6BYQ/WZXTVo7Up5hYtE64ccaqohE0Hcli/L4t1qdms2nOMEpumb1QIL17dkzG9Wju1brsQziDJ31lSlgPK1PJxVMdR0Ply+OVV6Hmd6Q5yB9mpkHMAht5ndSRu6UhOAQn7skhIzWbD/my2Hsql1GbKUXVsGcRtcdFcFxtJx3CZuCbclyR/Z0lZZoZEBoZW73Hx/4F3BsLSp03xM3dwup5PeYu1NzAlpTZ2HMlj/b7sMz8Hj+cD4O/rRZ/IEO4c3p7YdqH0i2pG00Bp4Yv6QZK/MxTmQdq66tWqP61ZtOny+eUl6H+be1xg3bsSGreEFp2tjsTlcguKSdx/nIR92azfl0Xi/uOcLCoFILxJI2LbhXLHsBhio5vRtXUTWQRF1FuS/J0hdRXYShzv7z/XsAdg02fm4u/fVjivjk5NaG1a/tHD6k/9oUrYbJq8ghJy8ovJLSgmJ//sn9wy9/ekn2Dn0Ty0Bi8FXVo14Zr+EfRv14z+7ZrRNiRALtYKjyHJ3xlSloOPP0QOrtnjfQPgkhdhzo2w7gOzCIxVMpMh77B7fAOpQIi9Z44AABmQSURBVF5BMQey8jmQfYoDWadIzys8K4mfSfSniskrLEFXsjqEj5eiaYAvTQJ8iWgWQHyPVsS2C6V3ZFO5SCs8miR/Z0hZbipf+tZi3HaXy6HDRbDsP2bFr6CWTguvWlJXmNva1u+vhYLiUtKyTXJPyzrFgex8DmSdsif7fHLyi8863s/Hi6YBvmd+wpv407Fl0Jnfm5TZV/Z+0wBfAv28pTUvGiRJ/rWVexgytptSDbWhFFz6MkwZAj8+B+OmOCW8atu7EoJbQ/MOdfo02SeL2H4490xCP92KP5CdT0Ze4VnH+nl7EdEsgIjQQHpHhBAZGkhks0AiQwOIaBZIs0BfSeBCVJMk/9qqqIRzTYR1NJO/Vr1hyh1HDqz9OavjdH9/+5FO7+9Pyz5FQmo2v6dmsW5vFrvTT5zZ5+2laN3Un4hmAYzo1MIk99AAe4IPpEVQI7y8JLkL4UyS/GsrZbmZCRve0znnu+AR2DwHFjwMf13m2qJqGTvgZEath3jabGZd2d9Ts0iwJ/tDOQUABDfyoV+7Zozr25beESG0ax5Iq6b+MmpGCBeT5F8bWpv6/e2HO28mbKMgU/jtqztgw0cQe7tzzuuIGtbzKSwpJelgDr/vzSYhNYuEfdln+uVbBjdiQEwok9s1Y0BMKF1aNcFbWvFCWE6Sf21k7IQTRyov4VwTPa6BhA/hp+fN2rbVnThWU6kroGlUlWWm8wqKWb8v+0w3zqYDxykssQHQvkVjLu3RitjoUAZGhxIZKsMjhXBHkvxrw9ESztWllFn0Zer5ZqHzMf/n3POXx2aD1F+h82V/2pVXUExCajZrUjJZk5zJ1kM52LTpq+/Rpgk3DW7HgOhQYqObERbkZgXqhBDlkuRfGynLIbQ9NGvn/HOHdze19H+bCv1uhTZ9nP8cZaVvhfxsiD6fk4UlJOzLZk1yJmtSMkk6mEOpTePn7UWfqBDuvbAjg2JC6RMZQmNZXlCIeqnK/7lKqRnAGCBda92jnP0jgG+BvfZNX2utn7fvSwXygFKgRGsd65yw3UBpsWkp97qu7p5jxOOQ9CUseARuX1xnFTbzi0o5vG4R7YG/rgxg2RdLKLFpfLwUfSJDuHtEB4a0b06/ds3w95VVvYTwBI4022YC7wAfV3LMSq31mAr2jdRaH6tuYG4vLQGKTji/y6esgBAY9S/49m7Y/Dn0meiU0xYUl7JhfzZr7S37xAPHmeK1AG+vcI55t2DyBc0Z0qE5/ds1I9BPWvZCeKIq/2drrVcopaLrPpR65kwJ5zqeCdv7Blj/ISx9xswC9m9a7VNordlyMIefd6SzJjmTjQeOU1Riw0tBz7ZNuSMuipEbd6O7X8W8cXF18EcIIdyNs5p1Q5RSm4BDwMNa66327RpYopTSwHta62kVnUApNRmYDBAVFeWksOpQyjJo0xcCmtXt83h5wWWvwrSRsPwliH/RoYcVldhYm5LJkm1H+HFbOkdyC1AKurdpwq1D2jG4fXMGxITSxN/XLETzex50qMZaBEKIes0ZyX8D0E5rfUIpdRnwDdDRvi9Oa31IKdUSWKqU2qG1XlHeSewfDNMAYmNjKynF5QYKck23z7AHXPN8bfqaGb+/vQd9b4bwbuUelltQzPKdGSzZeoRfdmaQV1hCgK83F3QK4+FunbmwS0tCG/v9+YGn6/dHD6u7v0EI4VZqnfy11rll7i9QSk1RSoVprY9prQ/Zt6crpeYBA4Fyk3+9sm8V6NK67e8/10XPwLZvTNnnW78/U37hcE4+P247ypJtR1mbkklxqSYsyI/Lerbm4m7hDOsYVvVF2r0rIawTBLdywR8ihHAHtU7+SqlWwFGttVZKDQS8gEylVGPAS2udZ78/Gni+ts/nFpKXgU8ARA5y3XMGhsKFT8MPD3Fw1Sy+LhzEkm1H2XIwB4CYsMbcHhfDxd3C6RvVzPFZtKXFsH8N9Lq+DoMXQrgbR4Z6zgZGAGFKqTTgWcAXQGs9FbgWuEspVQLkAxPsHwThwDz77E4f4DOt9aI6+StcLWU5tBtqFmF3gZJSGwn7svnxyECuU+0JXvo0/yt8jU6RrXg0vjOju4XToUVQzWbSHtpoRi25cf1+IYTzOTLa54Yq9r+DGQp67vYUoHfNQ3NTOQfh2E7oe1OdP1X2ySI+XJ3Kp2v3kXWyCD9vL4i4j6eOPsC68zfS+PIXav8ke0/X75fkL0RDIoO4q8uZJZwrcDgnn/dX7GX27/vJLy5lVNdwru7Xlgs6tSCokQ/M+53G66fCoEkQdl7tnix1JbTsDo3DnBK7EKJ+kORfXSnLITDMJExnnzrjBFN/SWbexoPYNIzt04Y7h3egU3jw2QeOeg52zDcXf2/6qua190sKYf9v0P/W2oYuhKhnJPlXh9Ym+bcf4dRSC0kHc/jf8mQWJB3Gz9uLGwZG8dfz2xMZGlj+A4LDYcQTsPgJ2LnATP6qiYProSRfunyEaIAk+VdH+nY4cdQpQzy11vy2N4spy5NZsSuD4EY+3DW8A7fFxdAi2IELyQP/Chs+hkWPQ4cLzSLw1bV3JaAgWmb1CtHQSPKvDieUcNZa89P2dKYs38OG/ccJC/Lj0fjO3DS4nZlt6yhvX1P2+aMrYNWbpghcdaWuhFY9636WshDC7Ujyr46U5dD8PAiJrPZDS0pt/LDlMFOWJbPzaB5tQwL499jujI+NrHmlzJgLoPvV8Ov/mQXkq1iE5SzF+XDgN1M2WgjR4Ejyd1RJEaSugj6Vjnz9k4LiUr5cn8a0FSnszzpFx5ZBvH5db67o3cY569aOfgF2LYLFT8KEWY4/7sDvUFok/f1CNFCS/B2Vtg6KTzq8ZGNRiY2Zq/fy/sq9ZOQV0icyhKcu78qoruF4OXMN26ZtzaLvP/0Ldv8IHUc59rjUlaC8zWQ1IUSDI8nfUSnLQXk5VPxs19E8HpyTyNZDuZzfMYw3J/RhSPvmdbeW7ZB7YOOnZuhnzBrHZh7vXWlWB/NvUjcxCSHcWt0sDeWJUpZBm35mgZUK2Gya6b/uZczbv3Ikp4BpN/fnkzsGMbRDWN0uYu7TCC59BbKSYe2Uqo8vOmmGeUqXjxANlrT8HVGQY5Ll+f+o8JCDx/N5ZO4mVidnMqprOC9d09O1i5l3HAWdL4dfXoWe15nuoIrsXwu2YqnnI0QDJi1/R6T+CtpW7hBPrTXzNqYR/8YKNh04zsvX9OT9W/q7NvGfFv8fsJXA0qcrPy51JXj5QORg18QlhHA7kvwdkbwMfAMhYuBZm7NPFnHvZxt5cM4mOocHs/D+C7h+QFTddvFUplk0DHsQkr6yT+CqwN4V0LY/NApyWWhCCPciyd8RKcuhXRz4/LEK1vKd6VzyxgqWbDvCo/GdmfO3IUQ1r6AcgysNewBCoszF39LiP+8vyIVDidLfL0QDJ8m/KjlpkLn7TJfPqaISnvpmC5M+XEdIoC/f3BPH3SPOc3zxlLrmGwCXvAjp22DdB3/ev3+NWYWsrheeF0K4NbngW5WU5ea2w0g27s/moS82kZp5kr8Mi+HhSzrXfHZuXepyOXS4CJb9B3pcA0Et/9i3dwV4+0HkwIofL4TweNLyr0rKcnTjlry+yYdrp66hsLiUWX8ZxFNjurln4gdT4vnSl00Jhx+fO3tf6kpz7aImheCEEB5Dkn9lbDZK9izjl5JuvPXzHsb2acOiBy9gaId6sPBJWEcz+StxlinlAJCfDYc3yxBPIYQk/4rYbJrvlv6IT/4xfi7qxpQb+/H6dX2qV3nTahc8AsGtYcHDYCuFfasBLRd7hRCS/MtzJKeAWz/8nc0rvgHgvr/8lct6trY4qhpoFGQKvx3eBBs+Mv39Pv4QEWt1ZEIIi1WZ/JVSM5RS6UqppAr2j1BK5SilEu0/z5TZF6+U2qmU2qOUqkHBeddLyz7FZW+tJCE1m9tap6LDOhHWtr3VYdVcj2ug3TD46XnYtRgiBzlW+0cI4dEcafnPBOKrOGal1rqP/ed5AKWUN/AucCnQDbhBKdWtNsHWteJSG/fN3khxiY3v74qlbc5GVPsRFkdVS0qZRV8KciF7rwzxFEIADiR/rfUKIKsG5x4I7NFap2iti4DPgbE1OI/LvPHjLjbsP85/ru7JeYXbofiUwyWc3Vp49z8WbYkZbm0sQgi34Kw+/yFKqU1KqYVKqe72bW2BA2WOSbNvK5dSarJSKkEplZCRkeGksBz36+5jTFmezIQBkVzRu429hLO356xvO+pZuOFz6e8XQgDOSf4bgHZa697A28A39u3lTXnVFZ1Eaz1Nax2rtY5t0aKFE8JyXEZeIQ9+kUiHFkE8e4X9sytlmUmU/k1dGkud8Q2AzpeabiAhRINX6+Svtc7VWp+w318A+CqlwjAt/bKL3UYAh2r7fM5ms2n+MXcTufnFvDOxLwF+3mY8/KGNtVqoXQgh3Fmtk79SqpWyl7FUSg20nzMTWAd0VErFKKX8gAnAd7V9Pmd7f2UKK3Zl8MwV3ejSyr6qVSUlnIUQwhNUWdtHKTUbGAGEKaXSgGcBXwCt9VTgWuAupVQJkA9M0FproEQpdS+wGPAGZmitt9bJX1FDG/dn8+rinVzWsxUTB0b9sSN5GfgFQcQA64ITQog6VGXy11rfUMX+d4B3Kti3AFhQs9DqVk5+MX+fvZHwJv68eHWvs2vwny7h7F2PZvMKIUQ1NMgZvlpr/vn1Fg7nFPD2xL40DSiT5I9uNWvhnneRdQEKIUQda5DJ//N1B/hhy2EeHt2ZflHNzt65bjp4N4Ke460JTgghXKDBJf9dR/N47rutnN8xjL9dcE7ZhsI82DwHelwNgaHWBCiEEC7QoJJ/flEp9362gWB/X16/rg9e566+tfkLKDoBsXdYE6AQQrhIg1rJ6/n529h19ASf3DGQFsHnFDfT2nT5tOops2CFEB6vwbT8528+xOzf93PXiA6c37GcGcQHfoP0rTDgLzILVgjh8RpE8j+QdYonvtpC36gQHrq4U/kHrZsOjZrIhV4hRIPg8cm/uNTGvbM3goK3JvTF17ucP/nkMdj2DfSeAH6NXR+kEEK4mMf3+b+2ZCebDhxnyo39iAwNLP+gjZ9AaRHE3u7a4IQQwiIe3fL/ZVcG7/2SwsRBURUvw2izQcKHZrWrll1dG6AQQljEY5N/em4BD81JpHN4MM+MqWQBseSf4Pg+GCCtfiFEw+GR3T42m+bBLxI5WVTC7ImD8ff1rvjgddOhcUvocoXrAhRCCIt5ZMv/f78ks2pPJs9d0Z1O4cEVH3h8P+xaBP1uBh8/1wUohBAW87jkv35fFq8v3cWYXq25fkBkFQfPNLf9J9V1WEII4VY8KvnnnCrmvtmJtAnx5z9X9zy7TPO5Sopgw8fQKR5Coio+TgghPJDH9PlrrXn8680czS3gy7uG0sS/ilr8O76HkxkwQOr4CCEaHo9p+efkF7P32Ekeje9Mn8iQqh+wbjqEtIMOUrdfCNHweEzLPyTQj2/uicOvvBm850rfDvtWwajnwMtjPv+EEMJhHpP8gcqHdJaVMAO8/aDvzXUbkBBCuKkqm71KqRlKqXSlVFIVxw1QSpUqpa4ts61UKZVo//nOGQHXWuEJ2PQ5dBsHjcOsjkYIISzhSMt/JmaB9o8rOkAp5Q28DCw+Z1e+1rpPjaOrC1vmQmGuXOgVQjRoVbb8tdYrgKwqDvs78BWQ7oyg6ozWkDAdWnaHyEFWRyOEEJap9dVOpVRb4Cpgajm7/ZVSCUqptUqpcbV9rlpLS4AjW0yrXxZsEUI0YM644PsG8JjWurScSVVRWutDSqn2wM9KqS1a6+TyTqKUmgxMBoiKqqNJVwnTwS8Iel1XN+cXQoh6whnjHGOBz5VSqcC1wJTTrXyt9SH7bQqwHOhb0Um01tO01rFa69gWLcpZZrG2TmVB0tfQ63poVEm9HyGEaABqnfy11jFa62itdTTwJXC31vobpVQzpVQjAKVUGBAHbKvt89XYxk+htFAu9AohBA50+yilZgMjgDClVBrwLOALoLUur5//tK7Ae0opG+ZD5iWttTXJ32YzY/sjB0N4d0tCEEIId1Jl8tda3+DoybTWk8rcXw30rFlYTpayDLL3wsgnrY5ECCHcQsOobbBuOgSGQbcrrY5ECCHcgucn/5w02LUQ+t4EPo2sjkYIIdyC5yf/9R+ZyV2xt1kdiRBCuA3PTv6lxWbBlo4XQ7Noq6MRQgi34dnJf8cPcOIIxMrwTiGEKMuzk/+6D6BplGn5CyGEOMNzk3/GLkhdCf1vBS8H6/wLIUQD4bnJP2EGePlCv1usjkQIIdyOZyb/opOQ+JkZ1x/U0upohBDC7Xhm8k/6Cgpz5EKvEEJUwDOT/7rp0KIrtBtqdSRCCOGWPC/5H1wPhxMh9nZZsEUIISrgecl/3QzwbQy9r7c6EiGEcFuelfxPZUHSl9BrPPg3tToaIYRwW56V/DfNhpICudArhBBV8Jzkr7UZ2x8xAFr3sjoaIYRwa85YwN09FJ00o3vaj7A6EiGEcHuek/wbBcGVb1sdhRBC1Aue0+0jhBDCYZL8hRCiAXIo+SulZiil0pVSSVUcN0ApVaqUurbMtluVUrvtP7fWNmAhhBC152jLfyYQX9kBSilv4GVgcZltocCzwCBgIPCsUqpZjSIVQgjhNA4lf631CiCrisP+DnwFpJfZdgmwVGudpbXOBpZSxYeIEEKIuueUPn+lVFvgKmDqObvaAgfK/J5m3yaEEMJCzrrg+wbwmNa69Jzt5VVW0+WdQCk1WSmVoJRKyMjIcFJYQgghyuOscf6xwOfKVNEMAy5TSpVgWvojyhwXASwv7wRa62nANIDY2NhyPyCEEEI4h9LasTyrlIoG5mute1Rx3Ez7cV/aL/iuB/rZd28A+mutK71+oJTKAPY5FNifhQHHavhYq9S3mOtbvCAxu0p9i7m+xQsVx9xOa93C0ZM41PJXSs3GtODDlFJpmBE8vgBa63P7+c/QWmcppf4NrLNver6qxG9/nMN/QDmxJmitY2v6eCvUt5jrW7wgMbtKfYu5vsULzovZoeSvtb7B0RNqrSed8/sMYEb1whJCCFGXZIavEEI0QJ6Y/KdZHUAN1LeY61u8IDG7Sn2Lub7FC06K2eELvkIIITyHJ7b8hRBCVEGSvxBCNED1NvkrpeKVUjuVUnuUUo+Xs7+RUmqOff9v9nkKllBKRSqllimltiultiql7i/nmBFKqRylVKL95xkrYj0nplSl1BZ7PAnl7FdKqbfsr/FmpVS/8s7jKkqpzmVev0SlVK5S6oFzjrH8dS6vSq5SKlQptdRe/XZpRQUQraqSW0HMryqldtj/7ecppUIqeGyl7yMXxvucUupgmX/7yyp4bKW5xcUxzykTb6pSKrGCx1b/NdZa17sfwBtIBtoDfsAmoNs5x9wNTLXfnwDMsTDe1kA/+/1gYFc58Y7ATI6z/PUtE1MqEFbJ/suAhZgyHoOB36yO+Zz3yBHMxBe3ep2BCzATH5PKbHsFeNx+/3Hg5XIeFwqk2G+b2e83szDm0YCP/f7L5cXsyPvIhfE+BzzswPum0tziypjP2f9f4Blnvcb1teU/ENijtU7RWhcBnwNjzzlmLPCR/f6XwEXKXn/C1bTWh7XWG+z384DteEaBu7HAx9pYC4QopVpbHZTdRUCy1rqmM8XrjC6/Sm7Z9+tHwLhyHmpZldzyYtZaL9Fal9h/XYsp3+IWKniNHeFIbqkTlcVsz13XAbOd9Xz1Nfk7Ui30zDH2N2gO0Nwl0VXC3v3UF/itnN1DlFKblFILlVLdXRpY+TSwRCm1Xik1uZz97ly1dQIV/0dxt9cZIFxrfRhMYwFoWc4x7vx63475Flieqt5HrnSvvZtqRgVda+76Gp8PHNVa765gf7Vf4/qa/B2pFupwRVFXUUoFYdY8eEBrnXvO7g2YLorewNvAN66OrxxxWut+wKXAPUqpC87Z73avMYBSyg+4Ephbzm53fJ0d5a6v95NACTCrgkOqeh+5yv+ADkAf4DCmG+VcbvkaAzdQeau/2q9xfU3+aUBkmd8jgEMVHaOU8gGaUrOvgU6hlPLFJP5ZWuuvz92vtc7VWp+w318A+Cqlwlwc5rkxHbLfpgPzMF+Jy3Lk38EKlwIbtNZHz93hjq+z3dHTXWb22/RyjnG719t+0XkMcKO2dz6fy4H3kUtorY9qrUu11jbg/QricMfX2Ae4GphT0TE1eY3ra/JfB3RUSsXYW3kTgO/OOeY74PRoiGuBnyt6c9Y1e3/ddGC71vr1Co5pdfqahFJqIObfJtN1Uf4pnsZKqeDT9zEX985dw/k74Bb7qJ/BQM7prguLVdhKcrfXuYyy79dbgW/LOWYxMFop1czeZTGaMsumuppSKh54DLhSa32qgmMceR+5xDnXo66qIA5HcourjQJ2aK3TyttZ49fYFVex6+jK+GWYUTPJwJP2bc9j3ogA/piv/XuA34H2FsY6DPPVcTOQaP+5DLgTuNN+zL3AVszogrXAUItf3/b2WDbZ4zr9GpeNWQHv2v8NtgCxbvC+CMQk86ZltrnV64z5YDoMFGNamndgrkf9BOy234baj40FPijz2Nvt7+k9wG0Wx7wH0z9++j19enRdG2BBZe8ji+L9xP4+3YxJ6K3Pjdf++59yi1Ux27fPPP3+LXNsrV9jKe8ghBANUH3t9hFCCFELkvyFEKIBkuQvhBANkCR/IYRogCT5CyFEAyTJXwghGiBJ/kII0QD9fw/gkMQ/t6vXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ind = np.random.choice(128)\n",
    "print(ind)\n",
    "plt.plot(output[ind,:,1].detach().cpu().numpy(), label='pred')\n",
    "# plt.plot(output[ind,:,1].detach().cpu().numpy(), label='pred_5')\n",
    "# plt.plot(output[ind,:,2].detach().cpu().numpy(), label='pred_9')\n",
    "\n",
    "plt.plot(batch['outputs'][ind,:,0], label='true')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
